Namespace(attSize=85, batch_size=128, beta1=0.5, class_embedding='att', classifier_lr=0.001, cls_weight=0.01, critic_iter=5, cuda=True, dataroot='/data0/docker/xingyun/f_xGAN/data', dataset='AWA1', drop_rate=0.2, gzsl=False, image_embedding='res101', lambda1=10.0, lr=1e-05, manualSeed=9182, matdataset=True, nclass_all=200, ndh=4096, nepoch=100, netD='', netD_name='MLP_CRITIC', netG='', netG_name='MLP_G', ngh=4096, ngpu=1, nrh=4096, nrh1=1024, nrh2=512, nrh3=312, nrh4=156, nz=85, outf='./checkpoint/', outname='awa', preprocessing=True, pretrain_classifier='', print_every=1, r_iteration=3, r_path='/home/xingyun/docker/cycle_clsgan/r_param/', r_weight=1, resSize=2048, save_every=100, standardization=False, start_epoch=0, syn_num=300, val_every=1, validation=False, workers=2)
Random Seed:  9182
cuda is on, sets the seed for generating random numbers on all GPU
# of training samples:  19832
MLP_G(
  (fc1): Linear(in_features=170, out_features=4096)
  (fc2): Linear(in_features=4096, out_features=2048)
  (lrelu): LeakyReLU(0.2, inplace)
  (relu): ReLU(inplace)
)
MLP_CRITIC(
  (fc1): Linear(in_features=2133, out_features=4096)
  (fc2): Linear(in_features=4096, out_features=1)
  (lrelu): LeakyReLU(0.2, inplace)
)
MLP_4HL_Dropout_R(
  (fc1): Linear(in_features=2048, out_features=1024)
  (fc2): Linear(in_features=1024, out_features=512)
  (fc3): Linear(in_features=512, out_features=312)
  (fc4): Linear(in_features=312, out_features=156)
  (fc5): Linear(in_features=156, out_features=85)
  (relu): ReLU(inplace)
  (lrelu): LeakyReLU(0.2, inplace)
  (dropout): Dropout(p=0.2)
)
epoch lossG lossD lossR wDistance c_errG acc
0 -0.5698 -0.2383 0.7555 0.5742 4.9469
unseen_class_acc=  0.14306577006354929
1 -1.4790 -0.0245 0.7666 1.5593 4.9630
unseen_class_acc=  0.26064137406647203
2 -1.9193 0.1265 0.7773 2.0391 4.7275
unseen_class_acc=  0.2988936699926853
3 -1.9597 -0.0263 0.7763 2.0589 5.2677
unseen_class_acc=  0.379037357121706
4 -1.7957 -0.1495 0.7859 1.8767 6.1509
unseen_class_acc=  0.3232453610748053
5 -1.5779 -0.2969 0.7919 1.6416 6.9231
unseen_class_acc=  0.3586630514357239
6 -1.3212 -0.4047 0.8206 1.3615 7.2346
unseen_class_acc=  0.3944329857826233
7 -1.1142 -0.4670 0.8497 1.1490 7.2250
unseen_class_acc=  0.477087986189872
8 -0.9721 -0.5644 0.8603 1.0095 6.6296
unseen_class_acc=  0.4581489585340023
9 -0.8981 -0.6853 0.8733 0.9265 6.4974
unseen_class_acc=  0.44893732070922854
10 -0.8416 -0.6011 0.8825 0.8715 6.4909
unseen_class_acc=  0.4543495289981365
11 -0.8210 -0.6728 0.8932 0.8566 5.6569
unseen_class_acc=  0.5268301695585251
12 -0.7852 -0.6673 0.9025 0.8142 4.7291
unseen_class_acc=  0.5243691585958004
13 -0.7972 -0.6165 0.9141 0.8291 4.8345
unseen_class_acc=  0.5876760512590409
14 -0.6772 -0.7350 0.9218 0.7023 3.3400
unseen_class_acc=  0.548512940108776
15 -0.7943 -0.5859 0.9224 0.8262 4.2504
unseen_class_acc=  0.5313676878809929
16 -0.8062 -0.6730 0.9261 0.8354 4.2728
unseen_class_acc=  0.5293246582150459
17 -0.8328 -0.6207 0.9326 0.8623 3.0787
unseen_class_acc=  0.5442344531416893
18 -0.8046 -0.7324 0.9343 0.8335 2.7381
unseen_class_acc=  0.549896939098835
19 -0.8490 -0.7899 0.9454 0.8833 2.5741
unseen_class_acc=  0.5534055054187774
20 -0.7791 -0.6595 0.9445 0.8087 2.1597
unseen_class_acc=  0.5309869930148124
21 -0.8295 -0.6750 0.9454 0.8653 2.5454
unseen_class_acc=  0.5759122982621193
22 -0.7716 -0.8161 0.9535 0.8045 2.4507
unseen_class_acc=  0.582079665362835
23 -0.7910 -0.8669 0.9511 0.8267 2.4594
unseen_class_acc=  0.5829268485307694
24 -0.7960 -0.7394 0.9553 0.8402 1.9458
unseen_class_acc=  0.6054888039827346
25 -0.8205 -0.6846 0.9581 0.8579 1.6320
unseen_class_acc=  0.6268143460154534
26 -0.8328 -0.8782 0.9613 0.8741 1.7520
unseen_class_acc=  0.6265674024820328
27 -0.8125 -0.8098 0.9607 0.8537 1.9014
unseen_class_acc=  0.625063619017601
28 -0.8375 -0.8739 0.9601 0.8767 1.8017
unseen_class_acc=  0.6417434751987457
29 -0.7937 -0.9549 0.9659 0.8337 1.5913
unseen_class_acc=  0.6357741549611091
30 -0.8266 -0.9512 0.9659 0.8625 1.4047
unseen_class_acc=  0.6449912041425705
31 -0.7732 -0.9596 0.9680 0.8014 1.3077
unseen_class_acc=  0.6467496529221535
32 -0.8595 -1.0494 0.9704 0.8932 1.4110
unseen_class_acc=  0.65327388048172
33 -0.7802 -0.9646 0.9694 0.8126 1.3526
unseen_class_acc=  0.6567510858178138
34 -0.7962 -0.9544 0.9697 0.8324 1.2361
unseen_class_acc=  0.657893830537796
35 -0.8349 -0.9526 0.9721 0.8795 1.0280
unseen_class_acc=  0.6629391059279441
36 -0.8388 -0.9941 0.9707 0.8723 0.8799
unseen_class_acc=  0.6609965354204178
37 -0.8580 -1.0135 0.9722 0.8916 1.2740
unseen_class_acc=  0.6596473425626754
38 -0.8205 -1.0782 0.9726 0.8566 1.3805
unseen_class_acc=  0.6697993963956833
39 -0.8199 -1.0851 0.9745 0.8545 1.0138
unseen_class_acc=  0.6804073184728623
40 -0.8342 -1.0377 0.9757 0.8765 1.1963
unseen_class_acc=  0.6723177269101143
41 -0.7848 -1.0556 0.9762 0.8154 0.9760
unseen_class_acc=  0.651779043674469
42 -0.8323 -1.1811 0.9757 0.8741 0.9945
unseen_class_acc=  0.6705366373062134
43 -0.8218 -0.9730 0.9756 0.8582 0.8638
unseen_class_acc=  0.6781390905380249
44 -0.8128 -1.2622 0.9783 0.8455 0.6093
unseen_class_acc=  0.6655371516942978
45 -0.8201 -1.3128 0.9780 0.8617 0.8681
unseen_class_acc=  0.6741795405745507
46 -0.8319 -1.2231 0.9793 0.8716 0.7212
unseen_class_acc=  0.6740952476859092
47 -0.7919 -1.1825 0.9813 0.8318 0.6137
unseen_class_acc=  0.6816513493657113
48 -0.8220 -1.3372 0.9807 0.8509 0.6515
unseen_class_acc=  0.6602526709437371
49 -0.8121 -1.2083 0.9808 0.8467 0.7206
unseen_class_acc=  0.6643917754292488
50 -0.7509 -1.3826 0.9833 0.7839 0.4968
unseen_class_acc=  0.6845886901021003
51 -0.8075 -1.3178 0.9812 0.8397 0.6944
unseen_class_acc=  0.6669699519872665
52 -0.7406 -1.1874 0.9815 0.7711 0.7628
unseen_class_acc=  0.6500079542398453
53 -0.7731 -1.3334 0.9817 0.8073 0.6764
unseen_class_acc=  0.6571371108293533
54 -0.7899 -1.3026 0.9824 0.8211 0.7198
unseen_class_acc=  0.6448922246694565
55 -0.7979 -1.2394 0.9835 0.8359 0.5624
unseen_class_acc=  0.6552962839603425
56 -0.7770 -1.3631 0.9836 0.8145 0.5756
unseen_class_acc=  0.6601412132382393
57 -0.7750 -1.3213 0.9828 0.8170 0.5764
unseen_class_acc=  0.6639341205358505
58 -0.7873 -1.2549 0.9842 0.8249 0.4454
unseen_class_acc=  0.6721034228801728
59 -0.8255 -1.2866 0.9851 0.8711 0.4292
unseen_class_acc=  0.6511638134717941
60 -0.8136 -1.4113 0.9853 0.8549 0.4130
unseen_class_acc=  0.6601470813155175
61 -0.7907 -1.2902 0.9862 0.8270 0.4630
unseen_class_acc=  0.6576555460691452
62 -0.7797 -1.3411 0.9853 0.8171 0.4273
unseen_class_acc=  0.666425558924675
63 -0.7304 -1.3262 0.9857 0.7634 0.4516
unseen_class_acc=  0.6507408261299134
64 -0.8146 -1.3878 0.9845 0.8518 0.7003
unseen_class_acc=  0.6423385232686997
65 -0.8140 -1.4319 0.9875 0.8536 0.3968
unseen_class_acc=  0.6428445369005203
66 -0.8185 -1.3185 0.9861 0.8567 0.3275
unseen_class_acc=  0.6382724687457084
67 -0.7499 -1.4175 0.9853 0.7837 0.3168
unseen_class_acc=  0.6599824413657188
68 -0.8133 -1.4216 0.9882 0.8490 0.3481
unseen_class_acc=  0.6591875672340393
69 -0.8125 -1.4076 0.9866 0.8479 0.5320
unseen_class_acc=  0.6654242724180222
70 -0.7872 -1.3838 0.9872 0.8342 0.5752
unseen_class_acc=  0.6396641254425048
71 -0.7987 -1.4256 0.9862 0.8357 0.5374
unseen_class_acc=  0.6468734949827194
72 -0.8087 -1.3104 0.9862 0.8433 0.2730
unseen_class_acc=  0.6400276958942414
73 -0.8220 -1.4290 0.9883 0.8624 0.3502
unseen_class_acc=  0.6322034567594528
74 -0.7901 -1.4306 0.9886 0.8192 0.2898
unseen_class_acc=  0.63625847697258
75 -0.8119 -1.3921 0.9883 0.8490 0.3178
unseen_class_acc=  0.6407526955008507
76 -0.7486 -1.5065 0.9896 0.7847 0.3998
unseen_class_acc=  0.6346793115139008
77 -0.7659 -1.4419 0.9883 0.8022 0.3334
unseen_class_acc=  0.6339874729514122
78 -0.7914 -1.4828 0.9893 0.8277 0.3248
unseen_class_acc=  0.6533322140574456
79 -0.8122 -1.5448 0.9899 0.8507 0.2835
unseen_class_acc=  0.6263715088367462
80 -0.7830 -1.4961 0.9899 0.8242 0.3217
unseen_class_acc=  0.6424906954169274
81 -0.7938 -1.5219 0.9899 0.8337 0.2697
unseen_class_acc=  0.6429802402853966
82 -0.7237 -1.5288 0.9898 0.7609 0.4013
unseen_class_acc=  0.6297277390956879
83 -0.7762 -1.5313 0.9901 0.8219 0.2367
unseen_class_acc=  0.6337727308273315
84 -0.7625 -1.4745 0.9902 0.7951 0.3722
unseen_class_acc=  0.6539441749453545
85 -0.8290 -1.4972 0.9904 0.8708 0.2867
unseen_class_acc=  0.6478661209344864
86 -0.7654 -1.4554 0.9898 0.7984 0.2801
unseen_class_acc=  0.6226388677954674
87 -0.8152 -1.4772 0.9904 0.8594 0.1712
unseen_class_acc=  0.6326444372534752
88 -0.8036 -1.4563 0.9905 0.8481 0.3197
unseen_class_acc=  0.6119855612516403
89 -0.8330 -1.5607 0.9912 0.8701 0.2742
unseen_class_acc=  0.6179111629724503
90 -0.7781 -1.4695 0.9903 0.8128 0.3391
unseen_class_acc=  0.6157057866454124
91 -0.8153 -1.4899 0.9914 0.8614 0.2200
unseen_class_acc=  0.6254077777266502
92 -0.7658 -1.4620 0.9909 0.7983 0.4169
unseen_class_acc=  0.6164506644010543
93 -0.7843 -1.4776 0.9909 0.8234 0.3248
unseen_class_acc=  0.6353577673435211
94 -0.8006 -1.5162 0.9917 0.8406 0.3919
unseen_class_acc=  0.6152623474597931
95 -0.7829 -1.5698 0.9904 0.8251 0.2969
unseen_class_acc=  0.6135215178132057
96 -0.7626 -1.5116 0.9910 0.7999 0.2165
unseen_class_acc=  0.6166933350265026
97 -0.8298 -1.4693 0.9922 0.8655 0.2521
unseen_class_acc=  0.6191658675670624
98 -0.7768 -1.5570 0.9912 0.8080 0.1326
unseen_class_acc=  0.6258120454847813
99 -0.8049 -1.5498 0.9916 0.8485 0.1578
unseen_class_acc=  0.6431706190109253
