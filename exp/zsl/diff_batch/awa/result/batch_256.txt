Namespace(attSize=85, batch_size=256, beta1=0.5, class_embedding='att', classifier_lr=0.001, cls_weight=0.01, critic_iter=5, cuda=True, dataroot='/data0/docker/xingyun/f_xGAN/data', dataset='AWA1', drop_rate=0.2, gzsl=False, image_embedding='res101', lambda1=10.0, lr=1e-05, manualSeed=9182, matdataset=True, nclass_all=200, ndh=4096, nepoch=100, netD='', netD_name='MLP_CRITIC', netG='', netG_name='MLP_G', ngh=4096, ngpu=1, nrh=4096, nrh1=1024, nrh2=512, nrh3=312, nrh4=156, nz=85, outf='./checkpoint/', outname='awa', preprocessing=True, pretrain_classifier='', print_every=1, r_iteration=3, r_path='/home/xingyun/docker/cycle_clsgan/r_param/', r_weight=1, resSize=2048, save_every=100, standardization=False, start_epoch=0, syn_num=300, val_every=1, validation=False, workers=2)
Random Seed:  9182
cuda is on, sets the seed for generating random numbers on all GPU
# of training samples:  19832
MLP_G(
  (fc1): Linear(in_features=170, out_features=4096)
  (fc2): Linear(in_features=4096, out_features=2048)
  (lrelu): LeakyReLU(0.2, inplace)
  (relu): ReLU(inplace)
)
MLP_CRITIC(
  (fc1): Linear(in_features=2133, out_features=4096)
  (fc2): Linear(in_features=4096, out_features=1)
  (lrelu): LeakyReLU(0.2, inplace)
)
MLP_4HL_Dropout_R(
  (fc1): Linear(in_features=2048, out_features=1024)
  (fc2): Linear(in_features=1024, out_features=512)
  (fc3): Linear(in_features=512, out_features=312)
  (fc4): Linear(in_features=312, out_features=156)
  (fc5): Linear(in_features=156, out_features=85)
  (relu): ReLU(inplace)
  (lrelu): LeakyReLU(0.2, inplace)
  (dropout): Dropout(p=0.2)
)
epoch lossG lossD lossR wDistance c_errG acc
0 -0.1689 0.3468 0.7184 0.1707 5.2141
unseen_class_acc=  0.17869241833686828
1 -0.6668 -0.2022 0.7469 0.6736 4.9404
unseen_class_acc=  0.18163071116432547
2 -1.1975 -0.0922 0.7587 1.2574 4.9504
unseen_class_acc=  0.1810091758146882
3 -1.6928 0.1117 0.7703 1.8073 4.7402
unseen_class_acc=  0.24106583297252654
4 -1.9153 0.1300 0.7767 2.0295 4.8293
unseen_class_acc=  0.3271230380982161
5 -1.9689 0.1160 0.7883 2.0723 4.8331
unseen_class_acc=  0.3246865326538682
6 -1.9849 0.0460 0.7811 2.0895 5.3995
unseen_class_acc=  0.34123131819069386
7 -1.8653 -0.0187 0.7855 1.9518 5.7149
unseen_class_acc=  0.3944946616422385
8 -1.7316 -0.1048 0.7905 1.8129 6.3334
unseen_class_acc=  0.4095057792961597
9 -1.6822 -0.1995 0.7869 1.7477 6.9240
unseen_class_acc=  0.421549912635237
10 -1.4826 -0.2961 0.8147 1.5356 6.6787
unseen_class_acc=  0.3965769588947296
11 -1.3844 -0.3886 0.8331 1.4323 7.0839
unseen_class_acc=  0.36678110286593435
12 -1.2636 -0.4392 0.8433 1.3121 7.2376
unseen_class_acc=  0.45743455477058886
13 -1.1565 -0.4691 0.8541 1.1978 7.1568
unseen_class_acc=  0.4253861039876938
14 -1.0416 -0.5177 0.8596 1.0755 7.1274
unseen_class_acc=  0.46933817490935326
15 -0.9862 -0.5768 0.8677 1.0189 6.8020
unseen_class_acc=  0.42685042023658754
16 -0.9821 -0.5844 0.8730 1.0154 6.9959
unseen_class_acc=  0.4517697362229228
17 -0.9397 -0.5565 0.8826 0.9711 5.9963
unseen_class_acc=  0.4635370343923569
18 -0.8985 -0.6592 0.8818 0.9288 5.9854
unseen_class_acc=  0.4683967411518097
19 -0.8769 -0.6203 0.8918 0.9116 5.3547
unseen_class_acc=  0.4814911186695099
20 -0.8765 -0.6359 0.8976 0.9070 5.7374
unseen_class_acc=  0.5177142105996608
21 -0.8669 -0.7563 0.9000 0.8971 5.2677
unseen_class_acc=  0.49536415189504623
22 -0.8356 -0.6167 0.9100 0.8661 4.5765
unseen_class_acc=  0.5346137292683124
23 -0.8237 -0.6748 0.9123 0.8526 4.6198
unseen_class_acc=  0.5172414861619472
24 -0.8454 -0.6575 0.9175 0.8759 4.3073
unseen_class_acc=  0.5557509444653987
25 -0.8311 -0.6180 0.9205 0.8618 3.9849
unseen_class_acc=  0.5172791462391615
26 -0.7766 -0.6115 0.9261 0.8068 4.2704
unseen_class_acc=  0.5494420617818833
27 -0.8235 -0.6649 0.9278 0.8518 3.6252
unseen_class_acc=  0.5320058628916741
28 -0.8104 -0.6591 0.9295 0.8440 3.1680
unseen_class_acc=  0.536602882295847
29 -0.8084 -0.6644 0.9365 0.8376 3.2156
unseen_class_acc=  0.508791321516037
30 -0.7662 -0.6611 0.9332 0.7956 3.0543
unseen_class_acc=  0.5391464605927467
31 -0.7999 -0.6857 0.9402 0.8323 2.9553
unseen_class_acc=  0.5502675771713257
32 -0.7888 -0.6669 0.9383 0.8281 3.2672
unseen_class_acc=  0.5697610303759575
33 -0.8300 -0.7384 0.9435 0.8633 2.7972
unseen_class_acc=  0.5688800483942031
34 -0.8265 -0.7628 0.9431 0.8621 2.5030
unseen_class_acc=  0.5732768565416336
35 -0.7922 -0.5882 0.9477 0.8330 2.3831
unseen_class_acc=  0.5814559817314148
36 -0.8158 -0.7303 0.9492 0.8509 2.7027
unseen_class_acc=  0.5487938165664673
37 -0.8602 -0.7539 0.9493 0.8991 2.5295
unseen_class_acc=  0.5767298638820648
38 -0.8324 -0.6713 0.9546 0.8729 2.2469
unseen_class_acc=  0.6085858643054962
39 -0.8648 -0.7279 0.9560 0.9008 2.1003
unseen_class_acc=  0.61949303150177
40 -0.8870 -0.6375 0.9572 0.9340 2.0247
unseen_class_acc=  0.6095974206924438
41 -0.8421 -0.7316 0.9573 0.8767 2.0745
unseen_class_acc=  0.613935923576355
42 -0.8863 -0.8978 0.9575 0.9261 1.8638
unseen_class_acc=  0.5951831579208374
43 -0.8634 -0.8769 0.9595 0.9065 1.8137
unseen_class_acc=  0.6294997438788414
44 -0.8003 -0.8199 0.9605 0.8365 1.8820
unseen_class_acc=  0.6162420868873596
45 -0.7978 -0.7704 0.9602 0.8358 1.6580
unseen_class_acc=  0.6256133019924164
46 -0.8403 -0.8937 0.9633 0.8776 1.6585
unseen_class_acc=  0.6221167981624603
47 -0.8847 -0.7539 0.9642 0.9276 1.6640
unseen_class_acc=  0.6496416375041008
48 -0.8576 -0.8528 0.9643 0.8928 1.6064
unseen_class_acc=  0.6578595325350761
49 -0.8341 -0.9010 0.9655 0.8673 1.4723
unseen_class_acc=  0.6365506023168563
50 -0.8459 -0.8180 0.9633 0.8857 1.4959
unseen_class_acc=  0.6456837624311447
51 -0.8443 -0.8075 0.9654 0.8811 1.4936
unseen_class_acc=  0.6513322994112969
52 -0.8414 -0.8961 0.9670 0.8786 1.3673
unseen_class_acc=  0.6504391431808472
53 -0.8614 -0.8591 0.9674 0.9013 1.6225
unseen_class_acc=  0.6644356638193131
54 -0.8253 -0.8773 0.9703 0.8615 1.4931
unseen_class_acc=  0.6456548944115639
55 -0.8917 -0.9737 0.9682 0.9299 1.2819
unseen_class_acc=  0.6555557891726493
56 -0.8751 -0.9373 0.9696 0.9142 1.3670
unseen_class_acc=  0.6649323403835297
57 -0.8359 -0.9092 0.9715 0.8699 1.0908
unseen_class_acc=  0.6619610697031021
58 -0.7956 -0.8937 0.9720 0.8309 1.0898
unseen_class_acc=  0.6606834232807159
59 -0.8457 -0.9495 0.9708 0.8862 1.0579
unseen_class_acc=  0.6666423961520195
60 -0.8272 -0.9137 0.9712 0.8658 1.2246
unseen_class_acc=  0.6453642398118973
61 -0.8207 -0.9353 0.9728 0.8592 1.0427
unseen_class_acc=  0.6716284126043319
62 -0.8582 -0.9611 0.9726 0.8933 1.2220
unseen_class_acc=  0.6626719295978546
63 -0.8679 -0.9417 0.9722 0.9066 1.1058
unseen_class_acc=  0.6586875870823861
64 -0.8311 -1.0862 0.9741 0.8705 1.0164
unseen_class_acc=  0.6654205054044724
65 -0.8088 -1.0289 0.9754 0.8451 0.9128
unseen_class_acc=  0.6531873568892479
66 -0.8421 -1.1549 0.9757 0.8782 1.1376
unseen_class_acc=  0.6650194510817528
67 -0.8501 -1.0546 0.9750 0.8862 0.8340
unseen_class_acc=  0.6708439379930496
68 -0.8139 -1.0407 0.9750 0.8476 0.9829
unseen_class_acc=  0.6685426786541939
69 -0.8451 -1.1181 0.9768 0.8840 0.7540
unseen_class_acc=  0.654566015303135
70 -0.8073 -1.1025 0.9766 0.8414 0.7080
unseen_class_acc=  0.6652757510542869
71 -0.8362 -1.0212 0.9775 0.8761 0.8635
unseen_class_acc=  0.6570728898048401
72 -0.8071 -1.1171 0.9781 0.8452 0.5881
unseen_class_acc=  0.6744155272841453
73 -0.8189 -1.0165 0.9788 0.8572 0.7530
unseen_class_acc=  0.6645763471722603
74 -0.8056 -1.1278 0.9772 0.8409 0.9580
unseen_class_acc=  0.6751539081335067
75 -0.8547 -1.1449 0.9772 0.8956 0.8833
unseen_class_acc=  0.6719181522727012
76 -0.8490 -1.1938 0.9791 0.8915 0.7203
unseen_class_acc=  0.6676620364189148
77 -0.8158 -1.1715 0.9787 0.8498 0.7379
unseen_class_acc=  0.6665037587285042
78 -0.8392 -1.1363 0.9795 0.8732 0.6457
unseen_class_acc=  0.6566158026456833
79 -0.8400 -1.2076 0.9791 0.8782 0.8180
unseen_class_acc=  0.677111043035984
80 -0.7913 -1.1439 0.9798 0.8277 0.8360
unseen_class_acc=  0.6711699321866036
81 -0.8012 -1.1273 0.9802 0.8363 0.7316
unseen_class_acc=  0.6675185769796371
82 -0.8306 -1.1492 0.9804 0.8680 0.7358
unseen_class_acc=  0.669963213801384
83 -0.8108 -1.1541 0.9799 0.8463 0.7092
unseen_class_acc=  0.6712020665407181
84 -0.8196 -1.1504 0.9822 0.8585 0.5435
unseen_class_acc=  0.6680613726377487
85 -0.7936 -1.2346 0.9831 0.8327 0.5372
unseen_class_acc=  0.6688792884349823
86 -0.8287 -1.1583 0.9821 0.8667 0.5197
unseen_class_acc=  0.6577663496136665
87 -0.8270 -1.2263 0.9814 0.8603 0.6191
unseen_class_acc=  0.666249468922615
88 -0.7660 -1.2852 0.9822 0.7965 0.5194
unseen_class_acc=  0.6552896440029145
89 -0.8186 -1.2732 0.9832 0.8650 0.6250
unseen_class_acc=  0.6666458949446679
90 -0.8355 -1.2519 0.9831 0.8764 0.6457
unseen_class_acc=  0.6685357421636582
91 -0.8060 -1.1887 0.9840 0.8371 0.4623
unseen_class_acc=  0.6503029793500901
92 -0.8261 -1.3065 0.9831 0.8682 0.6983
unseen_class_acc=  0.67056425511837
93 -0.7969 -1.2106 0.9836 0.8320 0.5784
unseen_class_acc=  0.6570028245449067
94 -0.8071 -1.2287 0.9839 0.8424 0.4383
unseen_class_acc=  0.6622462198138237
95 -0.8347 -1.2579 0.9839 0.8756 0.6013
unseen_class_acc=  0.6623553469777107
96 -0.8047 -1.2050 0.9849 0.8418 0.5455
unseen_class_acc=  0.6592835649847985
97 -0.8095 -1.1566 0.9840 0.8441 0.5243
unseen_class_acc=  0.6593384698033333
98 -0.7963 -1.2154 0.9847 0.8238 0.5510
unseen_class_acc=  0.6509950146079063
99 -0.8163 -1.3361 0.9845 0.8566 0.5018
unseen_class_acc=  0.6733629077672958
