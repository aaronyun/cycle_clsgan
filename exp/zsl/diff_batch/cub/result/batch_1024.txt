Namespace(attSize=312, batch_size=1024, beta1=0.5, class_embedding='att', classifier_lr=0.001, cls_weight=0.01, critic_iter=5, cuda=True, dataroot='/data0/docker/xingyun/f_xGAN/data', dataset='CUB1', drop_rate=0.2, gzsl=False, image_embedding='res101', lambda1=10.0, lr=0.0001, manualSeed=3483, matdataset=True, nclass_all=200, ndh=4096, nepoch=100, netD='', netD_name='MLP_CRITIC', netG='', netG_name='MLP_G', ngh=4096, ngpu=1, nrh=4096, nrh1=1024, nrh2=512, nrh3=312, nrh4=156, nz=312, outf='./checkpoint/', outname='cub', preprocessing=True, pretrain_classifier='', print_every=1, r_iteration=3, r_path='/home/xingyun/docker/cycle_clsgan/r_param/', r_weight=1, resSize=2048, save_every=100, standardization=False, start_epoch=0, syn_num=300, val_every=1, validation=False, workers=2)
Random Seed:  3483
cuda is on, sets the seed for generating random numbers on all GPU
# of training samples:  7057
MLP_G(
  (fc1): Linear(in_features=624, out_features=4096)
  (fc2): Linear(in_features=4096, out_features=2048)
  (lrelu): LeakyReLU(0.2, inplace)
  (relu): ReLU(inplace)
)
MLP_CRITIC(
  (fc1): Linear(in_features=2360, out_features=4096)
  (fc2): Linear(in_features=4096, out_features=1)
  (lrelu): LeakyReLU(0.2, inplace)
)
MLP_2HL_Dropout_R(
  (fc1): Linear(in_features=2048, out_features=1024)
  (fc2): Linear(in_features=1024, out_features=512)
  (fc3): Linear(in_features=512, out_features=312)
  (relu): ReLU(inplace)
  (lrelu): LeakyReLU(0.2, inplace)
  (dropout): Dropout(p=0.2)
)
epoch lossG lossD lossR wDistance c_errG acc
0 -1.2185 1.5125 0.6229 1.2464 6.5551
unseen_class_acc=  0.020206691175699235
1 -0.7215 -0.0639 0.6970 0.7315 6.2360
unseen_class_acc=  0.02433333396911621
2 -1.0937 -0.5541 0.7273 1.1083 6.0525
unseen_class_acc=  0.03325764708220959
3 -1.2009 -0.5281 0.7372 1.2125 5.9985
unseen_class_acc=  0.030763923339545727
4 -1.4482 -0.6880 0.7365 1.4664 6.1142
unseen_class_acc=  0.03592090435326099
5 -1.6815 -0.3722 0.7455 1.7185 6.0482
unseen_class_acc=  0.03854572091251612
6 -1.8995 -0.3911 0.7428 1.9570 6.0866
unseen_class_acc=  0.038141243308782574
7 -2.0559 -0.2463 0.7472 2.1351 5.9978
unseen_class_acc=  0.05347745560109615
8 -2.1220 -0.2960 0.7507 2.2106 5.7345
unseen_class_acc=  0.05400665283203125
9 -2.1589 -0.3409 0.7499 2.2468 5.7542
unseen_class_acc=  0.06624515615403652
10 -2.2174 -0.3707 0.7500 2.3408 5.6841
unseen_class_acc=  0.09401772879064083
11 -2.2342 -0.3197 0.7518 2.4207 5.7887
unseen_class_acc=  0.09318431843072177
12 -2.2594 -0.4410 0.7527 2.3729 5.7720
unseen_class_acc=  0.0958401932939887
13 -2.2402 -0.4643 0.7535 2.3460 5.8695
unseen_class_acc=  0.1142297138646245
14 -2.2436 -0.4936 0.7531 2.3498 6.0020
unseen_class_acc=  0.12730511590838434
15 -2.2615 -0.5285 0.7571 2.3704 6.0853
unseen_class_acc=  0.12589128457009793
16 -2.2260 -0.4866 0.7574 2.3668 6.1843
unseen_class_acc=  0.14192067064344882
17 -2.2119 -0.5386 0.7561 2.3238 6.1933
unseen_class_acc=  0.14517029378563165
18 -2.1939 -0.5595 0.7606 2.3079 6.2602
unseen_class_acc=  0.1423126694560051
19 -2.1555 -0.5991 0.7581 2.2490 6.3547
unseen_class_acc=  0.1762035445868969
20 -2.1168 -0.5393 0.7630 2.2154 6.5171
unseen_class_acc=  0.15406333420425652
21 -2.0535 -0.5869 0.7669 2.1506 6.3869
unseen_class_acc=  0.17723336562514305
22 -2.0165 -0.6007 0.7669 2.1021 6.3710
unseen_class_acc=  0.18819521471858025
23 -1.9797 -0.5433 0.7730 2.0772 6.4240
unseen_class_acc=  0.19513935048133135
24 -1.9594 -0.5656 0.7756 2.0535 6.4995
unseen_class_acc=  0.2323235535249114
25 -1.9114 -0.6317 0.7892 1.9981 6.3296
unseen_class_acc=  0.2148684249073267
26 -1.8561 -0.5514 0.7983 1.9515 6.4260
unseen_class_acc=  0.22468009896576405
27 -1.8128 -0.5798 0.8092 1.8880 6.1534
unseen_class_acc=  0.22605433326214552
28 -1.7529 -0.5589 0.8210 1.8336 6.0815
unseen_class_acc=  0.23616216883063315
29 -1.7162 -0.5914 0.8252 1.7716 6.1537
unseen_class_acc=  0.2606332739815116
30 -1.6704 -0.5184 0.8333 1.7308 5.8884
unseen_class_acc=  0.28335327085107564
31 -1.6365 -0.5739 0.8363 1.7058 5.8086
unseen_class_acc=  0.2723454963043332
32 -1.5964 -0.4944 0.8417 1.6530 5.7777
unseen_class_acc=  0.2877727237343788
33 -1.5629 -0.5028 0.8463 1.6214 5.6450
unseen_class_acc=  0.2924186309427023
34 -1.5491 -0.4944 0.8551 1.6060 5.7176
unseen_class_acc=  0.29557718690484763
35 -1.5077 -0.4635 0.8608 1.5500 5.5306
unseen_class_acc=  0.31211983792483805
36 -1.5075 -0.4987 0.8641 1.5557 5.5826
unseen_class_acc=  0.32927587870508435
37 -1.4686 -0.5450 0.8725 1.5177 5.2314
unseen_class_acc=  0.30034814823418854
38 -1.4494 -0.3548 0.8777 1.4901 5.3119
unseen_class_acc=  0.31027191523462533
39 -1.4209 -0.4311 0.8777 1.4664 5.2316
unseen_class_acc=  0.30766088239848616
40 -1.4303 -0.4398 0.8814 1.4756 5.1271
unseen_class_acc=  0.33993240028619764
41 -1.4106 -0.4210 0.8805 1.4511 5.0893
unseen_class_acc=  0.33716077245771886
42 -1.3950 -0.4785 0.8845 1.4383 5.0329
unseen_class_acc=  0.3471879401803017
43 -1.3735 -0.5513 0.8858 1.4202 4.9484
unseen_class_acc=  0.35237492866814135
44 -1.3637 -0.4030 0.8883 1.4027 4.7887
unseen_class_acc=  0.34775866363197566
45 -1.3629 -0.4106 0.8887 1.4035 4.8371
unseen_class_acc=  0.3653035080432892
46 -1.3350 -0.4825 0.8932 1.3762 4.6813
unseen_class_acc=  0.3641455937922001
47 -1.3474 -0.3383 0.8932 1.3847 4.8111
unseen_class_acc=  0.38765388712286947
48 -1.3218 -0.4132 0.8941 1.3600 4.7840
unseen_class_acc=  0.3635214845091104
49 -1.3415 -0.3613 0.8944 1.3791 4.6393
unseen_class_acc=  0.3890828327834606
50 -1.2975 -0.4733 0.8987 1.3434 4.6893
unseen_class_acc=  0.38760793913155794
51 -1.3168 -0.3781 0.8976 1.3625 4.4583
unseen_class_acc=  0.3855674614012241
52 -1.2612 -0.4421 0.9023 1.2965 4.4114
unseen_class_acc=  0.3901705927401781
53 -1.2741 -0.4011 0.9015 1.3088 4.4275
unseen_class_acc=  0.407837458178401
54 -1.2719 -0.5022 0.9029 1.3088 4.5240
unseen_class_acc=  0.40220268338918685
55 -1.2584 -0.4352 0.9060 1.2973 4.4454
unseen_class_acc=  0.3978610833734274
56 -1.2836 -0.3654 0.9065 1.3176 4.3191
unseen_class_acc=  0.4183497580140829
57 -1.2641 -0.3825 0.9065 1.3018 4.2579
unseen_class_acc=  0.4110108644887805
58 -1.2558 -0.5812 0.9106 1.3011 4.1979
unseen_class_acc=  0.40604525242000816
59 -1.2338 -0.5216 0.9110 1.2712 4.1075
unseen_class_acc=  0.4426013480126858
60 -1.2188 -0.6625 0.9123 1.2592 4.0118
unseen_class_acc=  0.4333327133208513
61 -1.2487 -0.5423 0.9131 1.2886 3.9762
unseen_class_acc=  0.4495583031326532
62 -1.2138 -0.5016 0.9140 1.2515 3.9299
unseen_class_acc=  0.44659922786056994
63 -1.1998 -0.6039 0.9137 1.2414 3.9791
unseen_class_acc=  0.44839415222406387
64 -1.2157 -0.5358 0.9164 1.2535 3.7956
unseen_class_acc=  0.46389336355030536
65 -1.2262 -0.5198 0.9160 1.2619 3.8261
unseen_class_acc=  0.4459373941645026
66 -1.2153 -0.6518 0.9165 1.2506 3.8779
unseen_class_acc=  0.44006180342286827
67 -1.1780 -0.4809 0.9197 1.2109 3.7527
unseen_class_acc=  0.4511915393918753
68 -1.1710 -0.4850 0.9196 1.2087 3.7637
unseen_class_acc=  0.45735329870134594
69 -1.1836 -0.4917 0.9189 1.2214 3.6234
unseen_class_acc=  0.46001163095235825
70 -1.1831 -0.5307 0.9214 1.2174 3.6848
unseen_class_acc=  0.4619201343506575
71 -1.1852 -0.4093 0.9224 1.2183 3.7233
unseen_class_acc=  0.45132972232997415
72 -1.1889 -0.5933 0.9225 1.2242 3.6750
unseen_class_acc=  0.46033760137856006
73 -1.1481 -0.7051 0.9242 1.1815 3.4989
unseen_class_acc=  0.4611097449064255
74 -1.1809 -0.5117 0.9260 1.2187 3.4045
unseen_class_acc=  0.4676071457564831
75 -1.1716 -0.5068 0.9254 1.2086 3.6003
unseen_class_acc=  0.46520808808505537
76 -1.1573 -0.6450 0.9272 1.1958 3.4760
unseen_class_acc=  0.46852329034358264
77 -1.1537 -0.5735 0.9268 1.1898 3.5392
unseen_class_acc=  0.47093967877328397
78 -1.1475 -0.5893 0.9267 1.1859 3.4070
unseen_class_acc=  0.4695206745713949
79 -1.1449 -0.7661 0.9294 1.1848 3.3631
unseen_class_acc=  0.4739708734303713
80 -1.1635 -0.5353 0.9306 1.1978 3.2888
unseen_class_acc=  0.4683232016861439
81 -1.1421 -0.7858 0.9274 1.1774 3.3622
unseen_class_acc=  0.46497200287878515
82 -1.1294 -0.7322 0.9318 1.1659 3.2127
unseen_class_acc=  0.4730464120209217
83 -1.1436 -0.7569 0.9321 1.1868 3.3065
unseen_class_acc=  0.47074681900441645
84 -1.1323 -0.5767 0.9345 1.1661 3.1886
unseen_class_acc=  0.47754945114254954
85 -1.1339 -0.7228 0.9351 1.1691 3.1959
unseen_class_acc=  0.47469093710184096
86 -1.1293 -0.8156 0.9341 1.1691 3.1897
unseen_class_acc=  0.4597615863382816
87 -1.1111 -0.8057 0.9354 1.1471 3.0715
unseen_class_acc=  0.47619245402514937
88 -1.1209 -0.7469 0.9369 1.1538 3.2260
unseen_class_acc=  0.48873745068907737
89 -1.1100 -0.7582 0.9350 1.1470 3.1276
unseen_class_acc=  0.48042626313865183
90 -1.1290 -0.8753 0.9376 1.1667 3.0997
unseen_class_acc=  0.49297392278909685
91 -1.1169 -0.7085 0.9376 1.1514 3.1549
unseen_class_acc=  0.4826492894440889
92 -1.1318 -0.7904 0.9382 1.1687 2.9039
unseen_class_acc=  0.4788917598128319
93 -1.1079 -0.7957 0.9408 1.1421 2.9443
unseen_class_acc=  0.49509355597198007
94 -1.1066 -0.7500 0.9408 1.1425 2.9879
unseen_class_acc=  0.48753108888864516
95 -1.1315 -0.9540 0.9409 1.1665 2.8915
unseen_class_acc=  0.48362167984247206
96 -1.1117 -0.9140 0.9414 1.1452 2.9267
unseen_class_acc=  0.48181973308324816
97 -1.1199 -0.8853 0.9401 1.1568 2.9475
unseen_class_acc=  0.5012528626620769
98 -1.1086 -0.9120 0.9426 1.1445 2.7563
unseen_class_acc=  0.487834987193346
99 -1.1200 -0.9113 0.9412 1.1566 2.9262
unseen_class_acc=  0.5059198205173016
