Namespace(attSize=1024, batch_size=1024, beta1=0.5, class_embedding='att', classifier_lr=0.001, cls_weight=0.1, critic_iter=5, cuda=True, dataroot='/data0/docker/xingyun/f_xGAN/data', dataset='FLO', drop_rate=0.2, gzsl=False, image_embedding='res101', lambda1=10.0, lr=0.0001, manualSeed=806, matdataset=True, nclass_all=200, ndh=4096, nepoch=100, netD='', netD_name='MLP_CRITIC', netG='', netG_name='MLP_G', ngh=4096, ngpu=1, nrh=4096, nrh1=1024, nrh2=512, nrh3=312, nrh4=156, nz=1024, outf='./checkpoint/', outname='flowers', preprocessing=True, pretrain_classifier='', print_every=1, r_iteration=3, r_path='/home/xingyun/docker/cycle_clsgan/r_param/', r_weight=1, resSize=2048, save_every=100, standardization=False, start_epoch=0, syn_num=300, val_every=1, validation=False, workers=2)
Random Seed:  806
cuda is on, sets the seed for generating random numbers on all GPU
# of training samples:  5631
MLP_G(
  (fc1): Linear(in_features=2048, out_features=4096)
  (fc2): Linear(in_features=4096, out_features=2048)
  (lrelu): LeakyReLU(0.2, inplace)
  (relu): ReLU(inplace)
)
MLP_CRITIC(
  (fc1): Linear(in_features=3072, out_features=4096)
  (fc2): Linear(in_features=4096, out_features=1)
  (lrelu): LeakyReLU(0.2, inplace)
)
MLP_1HL_Dropout_R(
  (fc1): Linear(in_features=2048, out_features=4096)
  (fc2): Linear(in_features=4096, out_features=1024)
  (lrelu): LeakyReLU(0.2, inplace)
  (relu): ReLU(inplace)
  (dropout): Dropout(p=0.2)
)
epoch lossG lossD lossR wDistance c_errG acc
0 -4.2334 4.9872 0.5672 4.5054 7.4305
unseen_class_acc=  0.0695814742706716
1 -1.3712 -0.2713 0.6548 1.3848 5.5809
unseen_class_acc=  0.100270726531744
2 -1.2020 -1.3413 0.6781 1.2133 5.4748
unseen_class_acc=  0.06572311045601964
3 -1.5639 -1.5435 0.6897 1.5858 5.3298
unseen_class_acc=  0.0882446295581758
4 -1.6613 -1.6391 0.6956 1.6809 5.2745
unseen_class_acc=  0.12267582239583134
5 -1.7758 -1.5713 0.7001 1.7926 5.1879
unseen_class_acc=  0.10607206663116812
6 -1.8706 -1.5130 0.7027 1.8867 5.2319
unseen_class_acc=  0.15795744848437607
7 -2.0083 -1.4340 0.7039 2.0237 5.0882
unseen_class_acc=  0.1584945447742939
8 -2.1515 -1.2851 0.7080 2.1741 5.0328
unseen_class_acc=  0.16815914646722377
9 -2.2807 -1.1372 0.7077 2.3123 4.8492
unseen_class_acc=  0.14027563156560063
10 -2.3678 -1.0420 0.7120 2.4223 4.7565
unseen_class_acc=  0.22313970196992158
11 -2.3998 -1.0099 0.7097 2.4728 4.7398
unseen_class_acc=  0.2223066348116845
12 -2.4070 -0.9881 0.7118 2.4977 4.5997
unseen_class_acc=  0.18043414382264017
13 -2.4423 -0.8777 0.7088 2.5999 4.5329
unseen_class_acc=  0.16727729639969766
14 -2.4733 -0.7493 0.7132 2.7125 4.4740
unseen_class_acc=  0.15401276685297488
15 -2.5189 -0.6831 0.7146 2.7916 4.4789
unseen_class_acc=  0.19888534573838115
16 -2.5487 -0.6864 0.7152 2.7872 4.4340
unseen_class_acc=  0.21628566491417586
17 -2.5860 -0.7224 0.7156 2.8615 4.3854
unseen_class_acc=  0.22124498328194023
18 -2.6474 -0.7474 0.7161 2.8659 4.3939
unseen_class_acc=  0.19916756260208784
19 -2.6432 -0.8224 0.7187 2.8638 4.3858
unseen_class_acc=  0.20880503691732882
20 -2.6433 -0.8553 0.7196 2.8473 4.3261
unseen_class_acc=  0.1925404139328748
21 -2.6857 -0.8939 0.7199 2.8109 4.3648
unseen_class_acc=  0.22575687197968364
22 -2.6733 -0.8739 0.7212 2.7989 4.3116
unseen_class_acc=  0.19906479464843868
23 -2.7273 -0.8725 0.7202 2.8313 4.3033
unseen_class_acc=  0.21541272541508077
24 -2.7132 -0.8113 0.7230 2.8617 4.3233
unseen_class_acc=  0.18329246719367803
25 -2.7266 -0.8510 0.7244 2.8573 4.2621
unseen_class_acc=  0.236200043419376
26 -2.7499 -0.8257 0.7256 2.9043 4.2396
unseen_class_acc=  0.2673868082463741
27 -2.7388 -0.8343 0.7268 2.8664 4.1788
unseen_class_acc=  0.2499373324215412
28 -2.7466 -0.7721 0.7279 2.9594 4.1574
unseen_class_acc=  0.22592913210392
29 -2.7399 -0.8397 0.7294 2.8685 4.1419
unseen_class_acc=  0.23689257483929396
30 -2.7310 -0.8284 0.7313 2.8542 4.1922
unseen_class_acc=  0.2779344679787755
31 -2.7528 -0.8525 0.7316 2.8627 4.0998
unseen_class_acc=  0.26829257030040027
32 -2.7421 -0.8641 0.7335 2.8709 4.0808
unseen_class_acc=  0.27597692096605897
33 -2.7411 -0.8481 0.7350 2.8901 4.0264
unseen_class_acc=  0.2757773288525641
34 -2.7313 -0.7577 0.7376 2.9721 3.9835
unseen_class_acc=  0.32432345738634466
35 -2.7466 -0.7934 0.7385 2.9697 4.0057
unseen_class_acc=  0.24646212109364568
36 -2.7686 -0.8839 0.7370 2.8921 3.9494
unseen_class_acc=  0.30152979530394075
37 -2.7524 -0.8829 0.7379 2.8625 4.0620
unseen_class_acc=  0.2899076325818896
38 -2.7759 -0.8300 0.7395 2.9217 3.9007
unseen_class_acc=  0.3272679462097585
39 -2.7861 -0.8228 0.7412 2.9226 3.8510
unseen_class_acc=  0.327202576212585
40 -2.7653 -0.7583 0.7411 2.9346 3.8968
unseen_class_acc=  0.3500800972804427
41 -2.7727 -0.8564 0.7435 2.9254 3.7497
unseen_class_acc=  0.3342254674062133
42 -2.7277 -0.8380 0.7424 2.8378 3.8138
unseen_class_acc=  0.33403080152347686
43 -2.7341 -0.8267 0.7452 2.8704 3.7380
unseen_class_acc=  0.36438954565674064
44 -2.7203 -0.8257 0.7446 2.8386 3.6972
unseen_class_acc=  0.3545398238115013
45 -2.6937 -0.7556 0.7450 2.8956 3.6903
unseen_class_acc=  0.34152800105512143
46 -2.6967 -0.7928 0.7471 2.8435 3.6899
unseen_class_acc=  0.3397100042086095
47 -2.6936 -0.8203 0.7466 2.8355 3.6010
unseen_class_acc=  0.3265830342657864
48 -2.6864 -0.8212 0.7473 2.7918 3.5667
unseen_class_acc=  0.3695820102468133
49 -2.6702 -0.8256 0.7490 2.7684 3.5265
unseen_class_acc=  0.3672376366797835
50 -2.6392 -0.7154 0.7483 2.7874 3.5802
unseen_class_acc=  0.4129819630179554
51 -2.6413 -0.7762 0.7492 2.7590 3.4598
unseen_class_acc=  0.3509902164340019
52 -2.6312 -0.7498 0.7514 2.7376 3.5160
unseen_class_acc=  0.38249447736889125
53 -2.6512 -0.6550 0.7494 2.8296 3.3850
unseen_class_acc=  0.3506868509110063
54 -2.5988 -0.6625 0.7510 2.7539 3.4649
unseen_class_acc=  0.38968227310106157
55 -2.6167 -0.7076 0.7518 2.7545 3.3213
unseen_class_acc=  0.39214486493729056
56 -2.6036 -0.7149 0.7518 2.7235 3.3135
unseen_class_acc=  0.3938734738621861
57 -2.5877 -0.6808 0.7537 2.7130 3.2804
unseen_class_acc=  0.3639190489426255
58 -2.5712 -0.6596 0.7550 2.7040 3.2837
unseen_class_acc=  0.39956846805289387
59 -2.5308 -0.6703 0.7542 2.6416 3.3098
unseen_class_acc=  0.4423188981600106
60 -2.5660 -0.5679 0.7535 2.7346 3.2289
unseen_class_acc=  0.37103120908141135
61 -2.5544 -0.5803 0.7542 2.7183 3.2389
unseen_class_acc=  0.43441765680909156
62 -2.5230 -0.5094 0.7566 2.7064 3.1278
unseen_class_acc=  0.4335464010480791
63 -2.5548 -0.6268 0.7572 2.6741 3.0591
unseen_class_acc=  0.43378657000139353
64 -2.5302 -0.5317 0.7554 2.6708 3.0962
unseen_class_acc=  0.45062119588255883
65 -2.5361 -0.5097 0.7556 2.7070 3.0134
unseen_class_acc=  0.4038507526740432
66 -2.4940 -0.5963 0.7582 2.6308 3.0204
unseen_class_acc=  0.39270385694690046
67 -2.4915 -0.5731 0.7590 2.6216 2.8951
unseen_class_acc=  0.45989943388849497
68 -2.4878 -0.5206 0.7593 2.6187 2.9603
unseen_class_acc=  0.4614698291756213
69 -2.4883 -0.4310 0.7587 2.6712 2.9634
unseen_class_acc=  0.44749884866178036
70 -2.4542 -0.4527 0.7584 2.6120 2.8885
unseen_class_acc=  0.4491689503658563
71 -2.4353 -0.4209 0.7595 2.6226 2.9260
unseen_class_acc=  0.4478799158707261
72 -2.3958 -0.4170 0.7598 2.5769 2.8336
unseen_class_acc=  0.43638834822922945
73 -2.4102 -0.4572 0.7602 2.5688 2.7673
unseen_class_acc=  0.4657117469236255
74 -2.4098 -0.4104 0.7610 2.5820 2.7130
unseen_class_acc=  0.46889035757631065
75 -2.4049 -0.5366 0.7613 2.5094 2.6971
unseen_class_acc=  0.47131974510848523
76 -2.4071 -0.5234 0.7625 2.5208 2.6629
unseen_class_acc=  0.4829443711787462
77 -2.3613 -0.4033 0.7629 2.4817 2.6408
unseen_class_acc=  0.4449523787945509
78 -2.3614 -0.3907 0.7626 2.5031 2.6879
unseen_class_acc=  0.45988175086677074
79 -2.3963 -0.3987 0.7621 2.5478 2.6186
unseen_class_acc=  0.4540156600996852
80 -2.3489 -0.3724 0.7633 2.4902 2.6712
unseen_class_acc=  0.48370123002678156
81 -2.3512 -0.3129 0.7627 2.5128 2.5470
unseen_class_acc=  0.47455210965126754
82 -2.3267 -0.3252 0.7643 2.4659 2.5072
unseen_class_acc=  0.4605599449947476
83 -2.3319 -0.4844 0.7651 2.4298 2.5525
unseen_class_acc=  0.49094244055449965
84 -2.3241 -0.2777 0.7643 2.4742 2.4434
unseen_class_acc=  0.48507266156375406
85 -2.3139 -0.5107 0.7646 2.4012 2.4823
unseen_class_acc=  0.5109856490045785
86 -2.3285 -0.2762 0.7636 2.4696 2.5886
unseen_class_acc=  0.4795809084549546
87 -2.3057 -0.2269 0.7649 2.4836 2.6113
unseen_class_acc=  0.4591642152518034
88 -2.3087 -0.3320 0.7656 2.4219 2.4003
unseen_class_acc=  0.49099267143756153
89 -2.2815 -0.3806 0.7655 2.3854 2.3911
unseen_class_acc=  0.4844305794686079
90 -2.2619 -0.2825 0.7655 2.3756 2.4232
unseen_class_acc=  0.4982193145900965
91 -2.2714 -0.1877 0.7664 2.4058 2.3903
unseen_class_acc=  0.502478813007474
92 -2.2685 -0.3379 0.7661 2.3728 2.3403
unseen_class_acc=  0.512155307084322
93 -2.2411 -0.2384 0.7661 2.3699 2.4302
unseen_class_acc=  0.5216910298913717
94 -2.2594 -0.2960 0.7669 2.3646 2.2938
unseen_class_acc=  0.49154019467532634
95 -2.2612 -0.4228 0.7668 2.3464 2.2450
unseen_class_acc=  0.4878998391330242
96 -2.2127 -0.1669 0.7669 2.3529 2.2913
unseen_class_acc=  0.5101479621604085
97 -2.2380 -0.2651 0.7662 2.3503 2.3469
unseen_class_acc=  0.5062342327088117
98 -2.2017 -0.1992 0.7676 2.3355 2.2890
unseen_class_acc=  0.5033373553305864
99 -2.2099 -0.3336 0.7684 2.3045 2.2527
unseen_class_acc=  0.47902119532227516
