Namespace(attSize=1024, batch_size=512, beta1=0.5, class_embedding='att', classifier_lr=0.001, cls_weight=0.1, critic_iter=5, cuda=True, dataroot='/data0/docker/xingyun/f_xGAN/data', dataset='FLO', drop_rate=0.2, gzsl=False, image_embedding='res101', lambda1=10.0, lr=0.0001, manualSeed=806, matdataset=True, nclass_all=200, ndh=4096, nepoch=100, netD='', netD_name='MLP_CRITIC', netG='', netG_name='MLP_G', ngh=4096, ngpu=1, nrh=4096, nrh1=1024, nrh2=512, nrh3=312, nrh4=156, nz=1024, outf='./checkpoint/', outname='flowers', preprocessing=True, pretrain_classifier='', print_every=1, r_iteration=3, r_path='/home/xingyun/docker/cycle_clsgan/r_param/', r_weight=1, resSize=2048, save_every=100, standardization=False, start_epoch=0, syn_num=300, val_every=1, validation=False, workers=2)
Random Seed:  806
cuda is on, sets the seed for generating random numbers on all GPU
# of training samples:  5631
MLP_G(
  (fc1): Linear(in_features=2048, out_features=4096)
  (fc2): Linear(in_features=4096, out_features=2048)
  (lrelu): LeakyReLU(0.2, inplace)
  (relu): ReLU(inplace)
)
MLP_CRITIC(
  (fc1): Linear(in_features=3072, out_features=4096)
  (fc2): Linear(in_features=4096, out_features=1)
  (lrelu): LeakyReLU(0.2, inplace)
)
MLP_1HL_Dropout_R(
  (fc1): Linear(in_features=2048, out_features=4096)
  (fc2): Linear(in_features=4096, out_features=1024)
  (lrelu): LeakyReLU(0.2, inplace)
  (relu): ReLU(inplace)
  (dropout): Dropout(p=0.2)
)
epoch lossG lossD lossR wDistance c_errG acc
0 -1.6085 0.2847 0.6504 1.6300 5.6117
unseen_class_acc=  0.07490637386217713
1 -1.4508 -1.5962 0.6852 1.4699 5.3827
unseen_class_acc=  0.050984885543584824
2 -1.7285 -1.5740 0.6967 1.7486 5.2571
unseen_class_acc=  0.12679177317768336
3 -1.9976 -1.3540 0.7012 2.0198 5.1766
unseen_class_acc=  0.1845273499377072
4 -2.1885 -1.2758 0.7091 2.2134 5.0335
unseen_class_acc=  0.17281933301128447
5 -2.3608 -1.0508 0.7105 2.4222 4.8348
unseen_class_acc=  0.17183069009333848
6 -2.4210 -0.9470 0.7125 2.5285 4.7371
unseen_class_acc=  0.18553044069558383
7 -2.4826 -0.8730 0.7088 2.6361 4.4892
unseen_class_acc=  0.21328107519075273
8 -2.5399 -0.8266 0.7165 2.6633 4.4821
unseen_class_acc=  0.18616169216111303
9 -2.6122 -0.7845 0.7130 2.7820 4.4495
unseen_class_acc=  0.2217280133627355
10 -2.7091 -0.8357 0.7187 2.9388 4.3925
unseen_class_acc=  0.13071453860029578
11 -2.7086 -0.8216 0.7209 2.9177 4.4543
unseen_class_acc=  0.22626226870343089
12 -2.7498 -0.8168 0.7199 2.8948 4.3680
unseen_class_acc=  0.193957201205194
13 -2.7412 -0.8716 0.7224 2.8655 4.2497
unseen_class_acc=  0.21123444349505008
14 -2.7648 -0.7695 0.7215 2.9457 4.2897
unseen_class_acc=  0.20264295875094832
15 -2.8215 -0.7447 0.7264 3.0444 4.2052
unseen_class_acc=  0.2533242902252823
16 -2.8462 -0.7940 0.7284 2.9901 4.2001
unseen_class_acc=  0.2604873778298497
17 -2.8291 -0.8336 0.7298 2.9821 4.1570
unseen_class_acc=  0.24230641340836884
18 -2.8804 -0.7901 0.7322 3.0852 4.1834
unseen_class_acc=  0.25359012819826604
19 -2.8440 -0.7856 0.7347 3.0482 4.1773
unseen_class_acc=  0.2774100804235786
20 -2.8270 -0.7407 0.7366 3.0706 4.0693
unseen_class_acc=  0.2609633732121438
21 -2.8751 -0.7931 0.7364 3.0322 4.0133
unseen_class_acc=  0.27954426780343056
22 -2.8743 -0.7699 0.7369 3.0432 3.9297
unseen_class_acc=  0.3503370836842805
23 -2.8387 -0.7675 0.7384 3.0468 3.8431
unseen_class_acc=  0.3031197311822325
24 -2.9047 -0.8402 0.7408 3.0514 3.8335
unseen_class_acc=  0.3596577808726579
25 -2.8037 -0.8089 0.7421 2.9513 3.8606
unseen_class_acc=  0.30157595393247905
26 -2.8514 -0.7392 0.7445 3.0902 3.7184
unseen_class_acc=  0.31339199682697655
27 -2.7627 -0.8183 0.7465 2.9199 3.5831
unseen_class_acc=  0.3505741301458329
28 -2.8189 -0.8422 0.7492 2.9956 3.5737
unseen_class_acc=  0.31815917477943
29 -2.7953 -0.7270 0.7462 2.9985 3.6543
unseen_class_acc=  0.3706692515872419
30 -2.7718 -0.7687 0.7477 2.9418 3.6136
unseen_class_acc=  0.34878754606470463
31 -2.7433 -0.7319 0.7491 2.9523 3.4114
unseen_class_acc=  0.3824790342245251
32 -2.7421 -0.6950 0.7512 2.9449 3.5959
unseen_class_acc=  0.376801850553602
33 -2.7362 -0.7385 0.7509 2.8989 3.4550
unseen_class_acc=  0.3880709196440876
34 -2.7309 -0.7023 0.7517 2.8960 3.4046
unseen_class_acc=  0.4124042336829007
35 -2.6871 -0.6744 0.7526 2.8694 3.2714
unseen_class_acc=  0.401845227740705
36 -2.6325 -0.7601 0.7550 2.7457 3.2539
unseen_class_acc=  0.3914353050291538
37 -2.6583 -0.7508 0.7542 2.7789 3.2313
unseen_class_acc=  0.4010977633763105
38 -2.5987 -0.6223 0.7549 2.7712 3.0406
unseen_class_acc=  0.4297677612863481
39 -2.6010 -0.6520 0.7572 2.7712 3.0502
unseen_class_acc=  0.42985911783762276
40 -2.5768 -0.6570 0.7578 2.7346 2.9634
unseen_class_acc=  0.42343483604490756
41 -2.6064 -0.6279 0.7601 2.7382 3.0089
unseen_class_acc=  0.4412000116892159
42 -2.5931 -0.4872 0.7599 2.7958 3.0913
unseen_class_acc=  0.44659536946564915
43 -2.5593 -0.6028 0.7597 2.7032 2.8624
unseen_class_acc=  0.4422180576249957
44 -2.5221 -0.4477 0.7593 2.7104 2.8348
unseen_class_acc=  0.45341530423611404
45 -2.5455 -0.6235 0.7618 2.6640 2.7434
unseen_class_acc=  0.46696805506944655
46 -2.5257 -0.5523 0.7624 2.6762 2.7091
unseen_class_acc=  0.4502696764655411
47 -2.4992 -0.4492 0.7627 2.6754 2.7488
unseen_class_acc=  0.4882925072684884
48 -2.4655 -0.5059 0.7621 2.6004 2.6201
unseen_class_acc=  0.484467270411551
49 -2.4360 -0.4192 0.7626 2.5789 2.7814
unseen_class_acc=  0.45864581018686296
50 -2.4550 -0.4122 0.7631 2.5984 2.6496
unseen_class_acc=  0.471314250305295
51 -2.3988 -0.3990 0.7647 2.5318 2.5735
unseen_class_acc=  0.48225463889539244
52 -2.4432 -0.3729 0.7644 2.5687 2.5597
unseen_class_acc=  0.47287576235830786
53 -2.3966 -0.3090 0.7648 2.5557 2.5765
unseen_class_acc=  0.4655345160514116
54 -2.3981 -0.2397 0.7661 2.5455 2.4482
unseen_class_acc=  0.4859366524964571
55 -2.3866 -0.2892 0.7662 2.5159 2.4330
unseen_class_acc=  0.4612284369766712
56 -2.3685 -0.1585 0.7678 2.5056 2.3561
unseen_class_acc=  0.48356492901220915
57 -2.3601 -0.1915 0.7684 2.5014 2.4433
unseen_class_acc=  0.4840481186285615
58 -2.3075 -0.1144 0.7657 2.4471 2.3595
unseen_class_acc=  0.5091195099055768
59 -2.3243 -0.1743 0.7683 2.4617 2.3889
unseen_class_acc=  0.48260535635054114
60 -2.3404 -0.2451 0.7670 2.4347 2.2981
unseen_class_acc=  0.5198477737605571
61 -2.2925 -0.0962 0.7693 2.4175 2.2544
unseen_class_acc=  0.5132971622049809
62 -2.2534 -0.1231 0.7699 2.3735 2.1515
unseen_class_acc=  0.48861585520207884
63 -2.2800 -0.0369 0.7681 2.4039 2.2181
unseen_class_acc=  0.49811572283506395
64 -2.2698 0.0049 0.7693 2.4140 2.1207
unseen_class_acc=  0.5174046110361814
65 -2.2064 -0.0850 0.7692 2.3151 2.1205
unseen_class_acc=  0.5200441770255566
66 -2.2284 0.0225 0.7680 2.3504 2.1730
unseen_class_acc=  0.4864885713905096
67 -2.1993 0.0362 0.7705 2.3060 2.1662
unseen_class_acc=  0.5055515963584185
68 -2.1942 0.1103 0.7705 2.3081 2.0653
unseen_class_acc=  0.49059600196778774
69 -2.1820 0.1004 0.7710 2.3055 2.2422
unseen_class_acc=  0.522124069929123
70 -2.1880 0.1754 0.7723 2.3230 2.0587
unseen_class_acc=  0.5038136564195156
71 -2.1483 0.1939 0.7707 2.2706 2.1426
unseen_class_acc=  0.523107412084937
72 -2.1321 0.1588 0.7704 2.2365 2.0135
unseen_class_acc=  0.5186896987259388
73 -2.1653 0.2638 0.7718 2.2793 2.0142
unseen_class_acc=  0.5152627047151327
74 -2.1052 0.2754 0.7729 2.2100 2.0262
unseen_class_acc=  0.5032551258802413
75 -2.1442 0.3130 0.7708 2.2625 2.1143
unseen_class_acc=  0.5305602960288525
76 -2.1132 0.3587 0.7717 2.2622 1.9401
unseen_class_acc=  0.5142508946359158
77 -2.0624 0.2397 0.7710 2.1393 1.9929
unseen_class_acc=  0.5352709323167801
78 -2.0378 0.3496 0.7730 2.1286 1.8733
unseen_class_acc=  0.5170688211917878
79 -2.0704 0.2939 0.7731 2.1461 1.9453
unseen_class_acc=  0.5014504261314869
80 -2.0456 0.3791 0.7736 2.1394 1.9874
unseen_class_acc=  0.5158697508275509
81 -2.0634 0.4931 0.7712 2.1679 1.8773
unseen_class_acc=  0.5358421832323075
82 -1.9874 0.4842 0.7722 2.0753 1.9344
unseen_class_acc=  0.5448790661990642
83 -1.9742 0.5149 0.7738 2.0571 1.9161
unseen_class_acc=  0.5240071006119251
84 -1.9843 0.5033 0.7735 2.0707 1.8605
unseen_class_acc=  0.5176088459789753
85 -1.9659 0.6145 0.7721 2.0805 1.8663
unseen_class_acc=  0.5288313493132591
86 -1.9313 0.5304 0.7737 2.0130 1.7503
unseen_class_acc=  0.5296813499182462
87 -1.9539 0.5934 0.7750 2.0438 1.7693
unseen_class_acc=  0.5360773116350174
88 -1.9043 0.6673 0.7744 1.9941 1.8045
unseen_class_acc=  0.5553174331784249
89 -1.9349 0.6925 0.7750 2.0420 1.8716
unseen_class_acc=  0.5455594811588526
90 -1.8905 0.6617 0.7749 1.9947 1.8556
unseen_class_acc=  0.5206263795495033
91 -1.8872 0.6808 0.7741 1.9901 1.7892
unseen_class_acc=  0.5803313978016377
92 -1.8557 0.6974 0.7750 1.9475 1.7492
unseen_class_acc=  0.5534056857228279
93 -1.8526 0.6627 0.7751 1.9319 1.7519
unseen_class_acc=  0.56220358684659
94 -1.8464 0.7023 0.7754 1.9289 1.8227
unseen_class_acc=  0.5631660562008619
95 -1.8687 0.6225 0.7771 1.9565 1.7151
unseen_class_acc=  0.5471873551607132
96 -1.8698 0.8048 0.7761 1.9724 1.8839
unseen_class_acc=  0.5552203603088856
97 -1.8325 0.7011 0.7767 1.9097 1.7337
unseen_class_acc=  0.5635929509997368
98 -1.7811 0.7613 0.7753 1.8636 1.5856
unseen_class_acc=  0.5686842367053032
99 -1.8202 0.7453 0.7759 1.8941 1.6373
unseen_class_acc=  0.5621890589594841
