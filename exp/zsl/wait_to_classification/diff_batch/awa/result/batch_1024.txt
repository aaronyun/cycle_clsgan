Namespace(attSize=85, batch_size=1024, beta1=0.5, class_embedding='att', classifier_lr=0.001, cls_weight=0.01, critic_iter=5, cuda=True, dataroot='/data0/docker/xingyun/f_xGAN/data', dataset='AWA1', drop_rate=0.2, gzsl=False, image_embedding='res101', lambda1=10.0, lr=1e-05, manualSeed=9182, matdataset=True, nclass_all=200, ndh=4096, nepoch=100, netD='', netD_name='MLP_CRITIC', netG='', netG_name='MLP_G', ngh=4096, ngpu=1, nrh=4096, nrh1=1024, nrh2=512, nrh3=312, nrh4=156, nz=85, outf='./checkpoint/', outname='awa', preprocessing=True, pretrain_classifier='', print_every=1, r_iteration=3, r_path='/home/xingyun/docker/cycle_clsgan/r_param/', r_weight=1, resSize=2048, save_every=100, standardization=False, start_epoch=0, syn_num=300, val_every=1, validation=False, workers=2)
Random Seed:  9182
cuda is on, sets the seed for generating random numbers on all GPU
# of training samples:  19832
MLP_G(
  (fc1): Linear(in_features=170, out_features=4096)
  (fc2): Linear(in_features=4096, out_features=2048)
  (lrelu): LeakyReLU(0.2, inplace)
  (relu): ReLU(inplace)
)
MLP_CRITIC(
  (fc1): Linear(in_features=2133, out_features=4096)
  (fc2): Linear(in_features=4096, out_features=1)
  (lrelu): LeakyReLU(0.2, inplace)
)
MLP_4HL_Dropout_R(
  (fc1): Linear(in_features=2048, out_features=1024)
  (fc2): Linear(in_features=1024, out_features=512)
  (fc3): Linear(in_features=512, out_features=312)
  (fc4): Linear(in_features=312, out_features=156)
  (fc5): Linear(in_features=156, out_features=85)
  (relu): ReLU(inplace)
  (lrelu): LeakyReLU(0.2, inplace)
  (dropout): Dropout(p=0.2)
)
epoch lossG lossD lossR wDistance c_errG acc
0 -1.1742 1.4227 0.5548 1.2214 5.5403
unseen_class_acc=  0.13807844552211462
1 -0.7236 0.8737 0.6415 0.7383 5.3213
unseen_class_acc=  0.13531451604794711
2 -0.2858 0.4672 0.6920 0.2883 5.2651
unseen_class_acc=  0.1132539824815467
3 -0.1602 0.2013 0.7206 0.1622 5.2115
unseen_class_acc=  0.1736502436455339
4 -0.2562 -0.0297 0.7306 0.2587 5.0049
unseen_class_acc=  0.11142123322933913
5 -0.4399 -0.1282 0.7406 0.4435 5.0952
unseen_class_acc=  0.14951878217980266
6 -0.6609 -0.2581 0.7474 0.6701 4.9694
unseen_class_acc=  0.15896095772041008
7 -0.8162 -0.2150 0.7567 0.8349 5.0313
unseen_class_acc=  0.1784165774472058
8 -0.9595 -0.0997 0.7562 0.9973 4.9889
unseen_class_acc=  0.18804014925844967
9 -1.1279 -0.1030 0.7616 1.1827 4.9274
unseen_class_acc=  0.1964127054437995
10 -1.2762 -0.0714 0.7633 1.3537 4.9330
unseen_class_acc=  0.2068430081009865
11 -1.4691 -0.0060 0.7649 1.5610 4.9955
unseen_class_acc=  0.1605803780257702
12 -1.6187 0.0685 0.7711 1.7241 4.8056
unseen_class_acc=  0.24507859498262405
13 -1.7387 0.1387 0.7762 1.8501 4.7059
unseen_class_acc=  0.20719609931111335
14 -1.8126 0.1576 0.7775 1.9252 4.6754
unseen_class_acc=  0.24035736341029407
15 -1.8819 0.1752 0.7784 1.9979 4.7221
unseen_class_acc=  0.3139663005247712
16 -1.9317 0.1846 0.7751 2.0521 4.8036
unseen_class_acc=  0.29042155742645265
17 -1.9594 0.1835 0.7827 2.0716 4.7166
unseen_class_acc=  0.33979550283402205
18 -1.9761 0.1747 0.7787 2.0880 4.8721
unseen_class_acc=  0.30650563929229974
19 -2.0009 0.1441 0.7800 2.1195 4.8730
unseen_class_acc=  0.3338405478745699
20 -2.0170 0.1197 0.7827 2.1344 4.9731
unseen_class_acc=  0.37184221716597676
21 -1.9958 0.1031 0.7842 2.1064 5.0566
unseen_class_acc=  0.34596050083637236
22 -1.9788 0.0895 0.7843 2.0844 5.1948
unseen_class_acc=  0.31868885476142167
23 -1.9981 0.0514 0.7833 2.1054 5.3873
unseen_class_acc=  0.42557432875037193
24 -1.9689 0.0375 0.7829 2.0711 5.6774
unseen_class_acc=  0.40277656614780427
25 -1.9589 -0.0033 0.7859 2.0614 5.6883
unseen_class_acc=  0.3960043709725142
26 -1.9457 -0.0197 0.7863 2.0492 5.8259
unseen_class_acc=  0.33036089669913055
27 -1.9228 -0.0587 0.7860 2.0186 6.0897
unseen_class_acc=  0.3231652050279081
28 -1.8734 -0.0677 0.7894 1.9642 6.4059
unseen_class_acc=  0.3875084828585386
29 -1.8448 -0.1023 0.7950 1.9294 6.4550
unseen_class_acc=  0.39067037850618364
30 -1.7873 -0.1036 0.7977 1.8652 6.4213
unseen_class_acc=  0.3711123697459698
31 -1.7724 -0.1419 0.8065 1.8514 6.4746
unseen_class_acc=  0.35122242039069534
32 -1.7591 -0.1623 0.8126 1.8336 6.7975
unseen_class_acc=  0.32844152823090556
33 -1.7006 -0.1988 0.8191 1.7753 6.8846
unseen_class_acc=  0.3891405165195465
34 -1.6595 -0.2005 0.8208 1.7259 6.9388
unseen_class_acc=  0.42354555502533914
35 -1.6247 -0.2377 0.8281 1.6913 7.0780
unseen_class_acc=  0.471096533536911
36 -1.5897 -0.2390 0.8340 1.6546 7.1445
unseen_class_acc=  0.444993844628334
37 -1.5517 -0.2639 0.8375 1.6132 7.4592
unseen_class_acc=  0.3397784195840359
38 -1.5197 -0.2952 0.8413 1.5821 7.1130
unseen_class_acc=  0.4312819572165608
39 -1.4555 -0.2862 0.8474 1.5082 7.1695
unseen_class_acc=  0.38542041964828966
40 -1.4229 -0.3126 0.8517 1.4747 7.3048
unseen_class_acc=  0.3959209308028221
41 -1.3879 -0.3406 0.8540 1.4376 7.3781
unseen_class_acc=  0.39987315572798254
42 -1.3403 -0.3444 0.8571 1.3875 7.5306
unseen_class_acc=  0.39264191761612893
43 -1.3331 -0.3393 0.8597 1.3790 7.4976
unseen_class_acc=  0.4201845645904541
44 -1.2990 -0.4258 0.8650 1.3446 7.1801
unseen_class_acc=  0.41576830577105284
45 -1.2670 -0.4137 0.8652 1.3108 7.0632
unseen_class_acc=  0.4325601186603308
46 -1.2230 -0.4213 0.8675 1.2638 7.1074
unseen_class_acc=  0.4496664732694626
47 -1.2123 -0.4333 0.8677 1.2535 7.1683
unseen_class_acc=  0.4394997026771307
48 -1.2124 -0.4625 0.8700 1.2539 6.9758
unseen_class_acc=  0.49102507792413236
49 -1.1890 -0.4843 0.8721 1.2278 7.0927
unseen_class_acc=  0.4820288710296154
50 -1.1686 -0.5099 0.8723 1.2082 6.8530
unseen_class_acc=  0.39675633907318114
51 -1.1349 -0.5380 0.8774 1.1731 6.6713
unseen_class_acc=  0.49709690660238265
52 -1.1149 -0.4987 0.8758 1.1518 6.6977
unseen_class_acc=  0.5139452319592237
53 -1.1148 -0.4987 0.8772 1.1517 6.7504
unseen_class_acc=  0.48022292256355287
54 -1.0826 -0.5184 0.8811 1.1201 6.4264
unseen_class_acc=  0.4631835751235485
55 -1.0503 -0.5143 0.8807 1.0854 6.6632
unseen_class_acc=  0.4760564282536507
56 -1.0522 -0.4996 0.8822 1.0883 6.4857
unseen_class_acc=  0.4852406706660986
57 -1.0673 -0.5577 0.8843 1.1020 6.1988
unseen_class_acc=  0.52917464338243
58 -1.0323 -0.5355 0.8858 1.0667 6.1594
unseen_class_acc=  0.5388943687081337
59 -1.0242 -0.5201 0.8873 1.0566 5.8987
unseen_class_acc=  0.41485136225819585
60 -1.0230 -0.5341 0.8933 1.0575 5.9011
unseen_class_acc=  0.46808542758226396
61 -1.0233 -0.5059 0.8900 1.0577 5.8122
unseen_class_acc=  0.48913467675447464
62 -1.0138 -0.5250 0.8934 1.0489 5.7193
unseen_class_acc=  0.4594817578792572
63 -0.9890 -0.4950 0.8960 1.0229 5.7782
unseen_class_acc=  0.5455580867826939
64 -0.9912 -0.5006 0.8973 1.0250 5.6998
unseen_class_acc=  0.444140662252903
65 -0.9752 -0.5319 0.8962 1.0082 5.3721
unseen_class_acc=  0.49210025891661646
66 -0.9831 -0.5007 0.8998 1.0157 5.3695
unseen_class_acc=  0.5023367598652839
67 -0.9784 -0.4719 0.9044 1.0114 5.4470
unseen_class_acc=  0.5111926138401032
68 -0.9662 -0.4751 0.9049 0.9991 5.0261
unseen_class_acc=  0.49340886920690535
69 -0.9803 -0.4447 0.9082 1.0147 5.0995
unseen_class_acc=  0.48535941541194916
70 -0.9847 -0.4358 0.9080 1.0188 5.0134
unseen_class_acc=  0.5185084193944931
71 -0.9555 -0.4500 0.9115 0.9904 4.7729
unseen_class_acc=  0.5223765775561333
72 -0.9739 -0.4959 0.9120 1.0062 4.9965
unseen_class_acc=  0.49461989514529703
73 -0.9840 -0.4879 0.9137 1.0189 4.8391
unseen_class_acc=  0.5298713207244873
74 -0.9713 -0.4491 0.9162 1.0046 4.6203
unseen_class_acc=  0.5206078946590423
75 -0.9525 -0.3902 0.9178 0.9897 4.5236
unseen_class_acc=  0.4939475804567337
76 -0.9499 -0.5143 0.9189 0.9843 4.5692
unseen_class_acc=  0.5026407606899739
77 -0.9414 -0.4696 0.9219 0.9746 4.4274
unseen_class_acc=  0.5452929735183716
78 -0.9456 -0.4542 0.9221 0.9775 4.3029
unseen_class_acc=  0.5338710255920887
79 -0.9562 -0.4586 0.9238 0.9905 4.1998
unseen_class_acc=  0.4915536653250456
80 -0.9617 -0.5247 0.9247 0.9956 3.8928
unseen_class_acc=  0.5063737407326698
81 -0.9552 -0.4806 0.9251 0.9905 4.2088
unseen_class_acc=  0.5338711850345135
82 -0.9257 -0.4261 0.9271 0.9625 3.9888
unseen_class_acc=  0.5497285351157188
83 -0.9366 -0.4854 0.9277 0.9698 3.8545
unseen_class_acc=  0.5451859474182129
84 -0.9477 -0.4748 0.9265 0.9827 3.8222
unseen_class_acc=  0.5199746340513229
85 -0.9362 -0.4245 0.9308 0.9756 3.6586
unseen_class_acc=  0.4812121219933033
86 -0.9488 -0.4940 0.9315 0.9861 3.5589
unseen_class_acc=  0.5233831942081452
87 -0.9257 -0.4637 0.9302 0.9634 3.6631
unseen_class_acc=  0.525141516327858
88 -0.9336 -0.4367 0.9319 0.9707 3.4620
unseen_class_acc=  0.5138802364468574
89 -0.9320 -0.4386 0.9327 0.9691 3.2547
unseen_class_acc=  0.5710458755493164
90 -0.9284 -0.4556 0.9346 0.9678 3.2712
unseen_class_acc=  0.5225279286503792
91 -0.9544 -0.3883 0.9352 0.9947 3.4260
unseen_class_acc=  0.540899533033371
92 -0.9549 -0.3918 0.9356 0.9972 3.1791
unseen_class_acc=  0.5554225444793701
93 -0.9263 -0.3906 0.9369 0.9668 3.3423
unseen_class_acc=  0.5394865602254868
94 -0.9558 -0.4269 0.9379 0.9966 3.1148
unseen_class_acc=  0.5396925985813141
95 -0.9530 -0.4368 0.9386 0.9958 3.0126
unseen_class_acc=  0.5230600804090499
96 -0.9434 -0.4598 0.9380 0.9842 2.9441
unseen_class_acc=  0.5645953930914402
97 -0.9447 -0.4729 0.9410 0.9878 2.9929
unseen_class_acc=  0.5375650450587273
98 -0.9690 -0.4191 0.9403 1.0108 2.9311
unseen_class_acc=  0.6112498611211776
99 -0.9682 -0.4790 0.9410 1.0102 2.8373
unseen_class_acc=  0.5812406077980995
