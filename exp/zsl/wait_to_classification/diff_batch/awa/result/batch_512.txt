Namespace(attSize=85, batch_size=512, beta1=0.5, class_embedding='att', classifier_lr=0.001, cls_weight=0.01, critic_iter=5, cuda=True, dataroot='/data0/docker/xingyun/f_xGAN/data', dataset='AWA1', drop_rate=0.2, gzsl=False, image_embedding='res101', lambda1=10.0, lr=1e-05, manualSeed=9182, matdataset=True, nclass_all=200, ndh=4096, nepoch=100, netD='', netD_name='MLP_CRITIC', netG='', netG_name='MLP_G', ngh=4096, ngpu=1, nrh=4096, nrh1=1024, nrh2=512, nrh3=312, nrh4=156, nz=85, outf='./checkpoint/', outname='awa', preprocessing=True, pretrain_classifier='', print_every=1, r_iteration=3, r_path='/home/xingyun/docker/cycle_clsgan/r_param/', r_weight=1, resSize=2048, save_every=100, standardization=False, start_epoch=0, syn_num=300, val_every=1, validation=False, workers=2)
Random Seed:  9182
cuda is on, sets the seed for generating random numbers on all GPU
# of training samples:  19832
MLP_G(
  (fc1): Linear(in_features=170, out_features=4096)
  (fc2): Linear(in_features=4096, out_features=2048)
  (lrelu): LeakyReLU(0.2, inplace)
  (relu): ReLU(inplace)
)
MLP_CRITIC(
  (fc1): Linear(in_features=2133, out_features=4096)
  (fc2): Linear(in_features=4096, out_features=1)
  (lrelu): LeakyReLU(0.2, inplace)
)
MLP_4HL_Dropout_R(
  (fc1): Linear(in_features=2048, out_features=1024)
  (fc2): Linear(in_features=1024, out_features=512)
  (fc3): Linear(in_features=512, out_features=312)
  (fc4): Linear(in_features=312, out_features=156)
  (fc5): Linear(in_features=156, out_features=85)
  (relu): ReLU(inplace)
  (lrelu): LeakyReLU(0.2, inplace)
  (dropout): Dropout(p=0.2)
)
epoch lossG lossD lossR wDistance c_errG acc
0 -0.7573 0.8877 0.6356 0.7738 5.4741
unseen_class_acc=  0.18408875884488224
1 -0.1709 0.3275 0.7114 0.1730 5.1668
unseen_class_acc=  0.09898030043113977
2 -0.3677 -0.0703 0.7343 0.3709 5.1804
unseen_class_acc=  0.1516151216812432
3 -0.7280 -0.1684 0.7493 0.7399 5.1765
unseen_class_acc=  0.14107331519480795
4 -1.0112 -0.1236 0.7609 1.0550 4.9919
unseen_class_acc=  0.17227192025166005
5 -1.3304 -0.0408 0.7716 1.4048 4.7502
unseen_class_acc=  0.28602573745884
6 -1.6065 0.0787 0.7741 1.7018 4.8827
unseen_class_acc=  0.2306894615292549
7 -1.8159 0.1590 0.7740 1.9444 4.7038
unseen_class_acc=  0.2649729013442993
8 -1.9112 0.1564 0.7807 2.0319 4.7031
unseen_class_acc=  0.26195406652987
9 -1.9442 0.1549 0.7784 2.0547 4.7659
unseen_class_acc=  0.3381357196718454
10 -1.9728 0.1355 0.7854 2.0909 4.8928
unseen_class_acc=  0.29592740144580604
11 -1.9998 0.0963 0.7817 2.1097 5.0288
unseen_class_acc=  0.33525416236370803
12 -1.9484 0.0466 0.7835 2.0520 5.4459
unseen_class_acc=  0.33502881759777664
13 -1.9201 -0.0089 0.7856 2.0210 5.6154
unseen_class_acc=  0.331566995754838
14 -1.9045 -0.0858 0.7884 1.9986 6.0920
unseen_class_acc=  0.3707115604542196
15 -1.8428 -0.1197 0.7947 1.9298 6.4436
unseen_class_acc=  0.43073606081306937
16 -1.7736 -0.1382 0.7945 1.8513 6.4132
unseen_class_acc=  0.42611534148454666
17 -1.7092 -0.1889 0.8013 1.7848 6.7463
unseen_class_acc=  0.4109755240380764
18 -1.6348 -0.2124 0.8125 1.7013 7.0285
unseen_class_acc=  0.3543847367167473
19 -1.5313 -0.2737 0.8243 1.5924 6.6960
unseen_class_acc=  0.35213571302592755
20 -1.4903 -0.3420 0.8326 1.5482 6.7917
unseen_class_acc=  0.48898455779999495
21 -1.4179 -0.3733 0.8412 1.4720 7.2394
unseen_class_acc=  0.3847172910347581
22 -1.3723 -0.3658 0.8484 1.4222 7.3435
unseen_class_acc=  0.46083602458238604
23 -1.3034 -0.3893 0.8520 1.3485 7.5029
unseen_class_acc=  0.4075854478403926
24 -1.2257 -0.4650 0.8592 1.2671 7.0821
unseen_class_acc=  0.43551946729421614
25 -1.1895 -0.4778 0.8630 1.2314 7.1706
unseen_class_acc=  0.4529618819244206
26 -1.1394 -0.5298 0.8644 1.1802 6.9318
unseen_class_acc=  0.4704376425594091
27 -1.0842 -0.5034 0.8648 1.1243 7.1587
unseen_class_acc=  0.5096115693449974
28 -1.0948 -0.5256 0.8741 1.1285 7.0847
unseen_class_acc=  0.419097800552845
29 -1.0324 -0.5545 0.8764 1.0685 6.5975
unseen_class_acc=  0.4325177036225796
30 -0.9802 -0.5320 0.8817 1.0139 6.3688
unseen_class_acc=  0.4722180914133787
31 -1.0235 -0.5736 0.8795 1.0595 6.3914
unseen_class_acc=  0.4750584945082664
32 -0.9992 -0.6243 0.8848 1.0285 6.2363
unseen_class_acc=  0.5101555787026882
33 -0.9578 -0.5872 0.8858 0.9864 5.9623
unseen_class_acc=  0.4764248073101044
34 -0.9282 -0.5882 0.8925 0.9601 5.8102
unseen_class_acc=  0.45968260057270527
35 -0.9160 -0.5729 0.8935 0.9468 5.6113
unseen_class_acc=  0.5089635506272316
36 -0.9252 -0.6745 0.8951 0.9551 5.0179
unseen_class_acc=  0.47603222727775574
37 -0.9147 -0.5945 0.8962 0.9476 5.4233
unseen_class_acc=  0.4762668624520302
38 -0.8816 -0.5930 0.9056 0.9103 4.9748
unseen_class_acc=  0.49100844413042066
39 -0.9261 -0.5478 0.9057 0.9594 4.9223
unseen_class_acc=  0.5106593057513237
40 -0.9210 -0.4957 0.9079 0.9528 5.1504
unseen_class_acc=  0.5447503179311752
41 -0.8892 -0.5261 0.9128 0.9194 4.6494
unseen_class_acc=  0.5098771795630455
42 -0.9090 -0.5440 0.9152 0.9413 4.4480
unseen_class_acc=  0.4939229220151901
43 -0.8773 -0.5693 0.9196 0.9079 4.2148
unseen_class_acc=  0.5020633652806282
44 -0.8790 -0.5607 0.9207 0.9095 4.2215
unseen_class_acc=  0.49579942375421526
45 -0.8906 -0.5110 0.9225 0.9221 4.2491
unseen_class_acc=  0.519818764925003
46 -0.8685 -0.5475 0.9250 0.9009 4.0074
unseen_class_acc=  0.5220243327319622
47 -0.8167 -0.6087 0.9282 0.8455 3.6561
unseen_class_acc=  0.5128744579851627
48 -0.8572 -0.4718 0.9293 0.8929 3.7032
unseen_class_acc=  0.49806505888700486
49 -0.8921 -0.5775 0.9301 0.9244 3.8128
unseen_class_acc=  0.5498729139566422
50 -0.8514 -0.5586 0.9320 0.8855 3.2733
unseen_class_acc=  0.5375115379691124
51 -0.8850 -0.5148 0.9337 0.9221 3.8149
unseen_class_acc=  0.5634605936706066
52 -0.8624 -0.6233 0.9348 0.8994 3.2965
unseen_class_acc=  0.5581420749425888
53 -0.8562 -0.5776 0.9375 0.8941 3.0626
unseen_class_acc=  0.5284222729504109
54 -0.8642 -0.5800 0.9383 0.8981 3.0600
unseen_class_acc=  0.5194785665720701
55 -0.8899 -0.5591 0.9387 0.9290 3.3804
unseen_class_acc=  0.5708852395415306
56 -0.8966 -0.4597 0.9404 0.9366 2.9101
unseen_class_acc=  0.587372462451458
57 -0.8323 -0.5556 0.9425 0.8680 2.6448
unseen_class_acc=  0.5600824601948261
58 -0.8809 -0.5609 0.9443 0.9195 2.5935
unseen_class_acc=  0.563015429675579
59 -0.9054 -0.5528 0.9441 0.9473 2.6935
unseen_class_acc=  0.59512550085783
60 -0.8996 -0.4803 0.9457 0.9433 2.8947
unseen_class_acc=  0.5821484491229058
61 -0.8762 -0.5321 0.9469 0.9200 2.5619
unseen_class_acc=  0.6033942878246308
62 -0.9519 -0.5787 0.9478 0.9957 2.5845
unseen_class_acc=  0.5514606922864914
63 -0.9187 -0.5550 0.9484 0.9631 2.4834
unseen_class_acc=  0.5773064270615578
64 -0.9101 -0.5443 0.9516 0.9505 2.3355
unseen_class_acc=  0.5880699440836906
65 -0.9137 -0.5481 0.9510 0.9535 2.4853
unseen_class_acc=  0.5847668826580048
66 -0.9109 -0.5582 0.9540 0.9528 2.1855
unseen_class_acc=  0.5963008388876915
67 -0.8675 -0.6249 0.9536 0.9048 2.2561
unseen_class_acc=  0.5867461755871772
68 -0.8939 -0.6062 0.9553 0.9322 2.1346
unseen_class_acc=  0.5941041633486748
69 -0.8807 -0.6369 0.9549 0.9210 2.2109
unseen_class_acc=  0.585245917737484
70 -0.8949 -0.6327 0.9578 0.9358 2.0407
unseen_class_acc=  0.6048379257321358
71 -0.8888 -0.5671 0.9578 0.9312 2.0674
unseen_class_acc=  0.6122169196605682
72 -0.8929 -0.6755 0.9578 0.9352 1.9110
unseen_class_acc=  0.6086584568023682
73 -0.8990 -0.6236 0.9590 0.9409 1.9715
unseen_class_acc=  0.6143945425748825
74 -0.9077 -0.6376 0.9575 0.9481 1.9461
unseen_class_acc=  0.6174011245369911
75 -0.8999 -0.6459 0.9606 0.9440 1.7642
unseen_class_acc=  0.6020358145236969
76 -0.8668 -0.7429 0.9605 0.9038 1.7478
unseen_class_acc=  0.6262099966406822
77 -0.8976 -0.6260 0.9602 0.9368 1.7228
unseen_class_acc=  0.6376599982380867
78 -0.9161 -0.6201 0.9617 0.9538 1.5631
unseen_class_acc=  0.6300513297319412
79 -0.8885 -0.6373 0.9598 0.9283 1.7825
unseen_class_acc=  0.6345625966787338
80 -0.8745 -0.6637 0.9625 0.9172 1.6622
unseen_class_acc=  0.6336823180317879
81 -0.9054 -0.6079 0.9635 0.9507 1.6147
unseen_class_acc=  0.6318418368697166
82 -0.8988 -0.6521 0.9635 0.9384 1.5643
unseen_class_acc=  0.6370807230472565
83 -0.9108 -0.6568 0.9626 0.9529 1.6499
unseen_class_acc=  0.6543937280774117
84 -0.9174 -0.6783 0.9661 0.9588 1.5109
unseen_class_acc=  0.6412616536021233
85 -0.8832 -0.6847 0.9668 0.9266 1.3077
unseen_class_acc=  0.6374013125896454
86 -0.9236 -0.7030 0.9635 0.9659 1.5233
unseen_class_acc=  0.6422217220067978
87 -0.9139 -0.7100 0.9654 0.9534 1.6396
unseen_class_acc=  0.6472623467445373
88 -0.9095 -0.7397 0.9655 0.9484 1.6762
unseen_class_acc=  0.6530245393514633
89 -0.8812 -0.7435 0.9673 0.9191 1.3719
unseen_class_acc=  0.6550333678722382
90 -0.9126 -0.8366 0.9664 0.9560 1.4071
unseen_class_acc=  0.654922616481781
91 -0.9071 -0.7375 0.9676 0.9488 1.2315
unseen_class_acc=  0.6490398615598678
92 -0.8940 -0.7570 0.9681 0.9338 1.2023
unseen_class_acc=  0.6520191788673401
93 -0.9004 -0.8115 0.9661 0.9404 1.3100
unseen_class_acc=  0.6455481633543968
94 -0.8627 -0.7115 0.9686 0.9013 1.4144
unseen_class_acc=  0.6592853531241417
95 -0.8762 -0.8150 0.9689 0.9147 1.3016
unseen_class_acc=  0.655159954726696
96 -0.8899 -0.7539 0.9690 0.9252 1.3181
unseen_class_acc=  0.6537969619035721
97 -0.8828 -0.7717 0.9692 0.9215 1.2652
unseen_class_acc=  0.6661512374877929
98 -0.9151 -0.7340 0.9687 0.9536 1.2361
unseen_class_acc=  0.6602261543273926
99 -0.8862 -0.7080 0.9712 0.9249 1.1539
unseen_class_acc=  0.6585215210914612
