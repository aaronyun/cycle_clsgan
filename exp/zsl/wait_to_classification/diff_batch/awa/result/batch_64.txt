Namespace(attSize=85, batch_size=64, beta1=0.5, class_embedding='att', classifier_lr=0.001, cls_weight=0.01, critic_iter=5, cuda=True, dataroot='/data0/docker/xingyun/f_xGAN/data', dataset='AWA1', drop_rate=0.2, gzsl=False, image_embedding='res101', lambda1=10.0, lr=1e-05, manualSeed=9182, matdataset=True, nclass_all=200, ndh=4096, nepoch=100, netD='', netD_name='MLP_CRITIC', netG='', netG_name='MLP_G', ngh=4096, ngpu=1, nrh=4096, nrh1=1024, nrh2=512, nrh3=312, nrh4=156, nz=85, outf='./checkpoint/', outname='awa', preprocessing=True, pretrain_classifier='', print_every=1, r_iteration=3, r_path='/home/xingyun/docker/cycle_clsgan/r_param/', r_weight=1, resSize=2048, save_every=100, standardization=False, start_epoch=0, syn_num=300, val_every=1, validation=False, workers=2)
Random Seed:  9182
cuda is on, sets the seed for generating random numbers on all GPU
# of training samples:  19832
MLP_G(
  (fc1): Linear(in_features=170, out_features=4096)
  (fc2): Linear(in_features=4096, out_features=2048)
  (lrelu): LeakyReLU(0.2, inplace)
  (relu): ReLU(inplace)
)
MLP_CRITIC(
  (fc1): Linear(in_features=2133, out_features=4096)
  (fc2): Linear(in_features=4096, out_features=1)
  (lrelu): LeakyReLU(0.2, inplace)
)
MLP_4HL_Dropout_R(
  (fc1): Linear(in_features=2048, out_features=1024)
  (fc2): Linear(in_features=1024, out_features=512)
  (fc3): Linear(in_features=512, out_features=312)
  (fc4): Linear(in_features=312, out_features=156)
  (fc5): Linear(in_features=156, out_features=85)
  (relu): ReLU(inplace)
  (lrelu): LeakyReLU(0.2, inplace)
  (dropout): Dropout(p=0.2)
)
epoch lossG lossD lossR wDistance c_errG acc
0 -1.1614 -0.0140 0.7631 1.2441 4.6092
unseen_class_acc=  0.21637112819589674
1 -1.8536 0.1175 0.7969 1.9630 4.5384
unseen_class_acc=  0.40365726202726365
2 -1.7421 -0.1405 0.7870 1.8203 6.2500
unseen_class_acc=  0.3635187010280788
3 -1.3073 -0.3456 0.8173 1.3508 7.2509
unseen_class_acc=  0.4221440628170967
4 -1.0685 -0.4926 0.8474 1.1029 7.8446
unseen_class_acc=  0.5064121771603822
5 -0.9514 -0.5452 0.8729 0.9806 7.9403
unseen_class_acc=  0.47068248838186266
6 -0.7682 -0.6030 0.8810 0.8028 5.5092
unseen_class_acc=  0.49717059135437014
7 -0.7673 -0.6612 0.8992 0.7984 4.6821
unseen_class_acc=  0.5143540509045124
8 -0.7521 -0.7901 0.9177 0.7733 4.4582
unseen_class_acc=  0.49091569036245347
9 -0.6788 -0.7819 0.9242 0.6988 3.3997
unseen_class_acc=  0.5108173348009586
10 -0.7301 -0.7299 0.9314 0.7592 3.0825
unseen_class_acc=  0.5390220686793328
11 -0.7789 -0.5514 0.9465 0.8205 2.3548
unseen_class_acc=  0.536969605088234
12 -0.8002 -0.7899 0.9484 0.8285 2.8107
unseen_class_acc=  0.5557692959904671
13 -0.8007 -0.8459 0.9479 0.8316 2.5894
unseen_class_acc=  0.5585161685943604
14 -0.6515 -0.7795 0.9547 0.6784 2.0129
unseen_class_acc=  0.5828447982668876
15 -0.8563 -0.6793 0.9569 0.9029 2.0903
unseen_class_acc=  0.6220935642719269
16 -0.7614 -1.0253 0.9633 0.7974 1.3785
unseen_class_acc=  0.6295073062181473
17 -0.8431 -0.9686 0.9624 0.8803 1.8379
unseen_class_acc=  0.6426549285650254
18 -0.8083 -0.9056 0.9647 0.8378 1.2114
unseen_class_acc=  0.6367508769035339
19 -0.7491 -0.8462 0.9685 0.7839 1.4891
unseen_class_acc=  0.6456220507621765
20 -0.8374 -0.8755 0.9672 0.8680 1.4366
unseen_class_acc=  0.6537480816245079
21 -0.8349 -0.9558 0.9704 0.8695 1.1672
unseen_class_acc=  0.6623975709080696
22 -0.8034 -1.0204 0.9727 0.8465 1.1152
unseen_class_acc=  0.6590445950627327
23 -0.8398 -1.0598 0.9711 0.8817 1.5145
unseen_class_acc=  0.6594285145401955
24 -0.8422 -1.1469 0.9701 0.8763 1.0243
unseen_class_acc=  0.646651791036129
25 -0.7483 -1.2557 0.9753 0.7853 1.1888
unseen_class_acc=  0.6650086253881454
26 -0.8673 -1.3171 0.9767 0.9018 0.8865
unseen_class_acc=  0.6605749443173409
27 -0.7347 -1.2931 0.9750 0.7594 0.7858
unseen_class_acc=  0.6488974675536155
28 -0.7711 -1.2677 0.9742 0.8010 1.2641
unseen_class_acc=  0.6779398277401925
29 -0.7277 -1.3606 0.9770 0.7525 0.6971
unseen_class_acc=  0.6733047008514405
30 -0.8073 -1.3785 0.9789 0.8483 1.1383
unseen_class_acc=  0.6597543090581894
31 -0.8130 -1.2686 0.9804 0.8444 0.6249
unseen_class_acc=  0.6864283442497253
32 -0.7375 -1.2272 0.9833 0.7716 0.4632
unseen_class_acc=  0.6539623156189919
33 -0.7932 -1.2054 0.9793 0.8278 0.7107
unseen_class_acc=  0.6433925092220306
34 -0.7884 -1.4196 0.9823 0.8223 1.0585
unseen_class_acc=  0.6646973669528962
35 -0.7423 -1.4358 0.9842 0.7810 0.3942
unseen_class_acc=  0.656400841474533
36 -0.7433 -1.3728 0.9836 0.7692 0.7334
unseen_class_acc=  0.6333650574088097
37 -0.7218 -1.3672 0.9858 0.7491 0.3110
unseen_class_acc=  0.6568321034312248
38 -0.8691 -1.4531 0.9823 0.9098 0.7198
unseen_class_acc=  0.6707363232970238
39 -0.8069 -1.5569 0.9845 0.8591 0.4288
unseen_class_acc=  0.6525370627641678
40 -0.7430 -1.5042 0.9874 0.7840 0.2651
unseen_class_acc=  0.6478670448064804
41 -0.7163 -1.5067 0.9846 0.7414 0.4563
unseen_class_acc=  0.6509971499443055
42 -0.7232 -1.5205 0.9882 0.7601 0.3399
unseen_class_acc=  0.6464982002973556
43 -0.8216 -1.6909 0.9888 0.8546 0.2887
unseen_class_acc=  0.6512880757451057
44 -0.7683 -1.5064 0.9853 0.8015 0.3766
unseen_class_acc=  0.6527581259608268
45 -0.7444 -1.5511 0.9888 0.7833 0.2993
unseen_class_acc=  0.6332653105258942
46 -0.8121 -1.5211 0.9879 0.8504 0.4786
unseen_class_acc=  0.6547653153538704
47 -0.7104 -1.6575 0.9881 0.7388 0.3062
unseen_class_acc=  0.6441848084330559
48 -0.8061 -1.4480 0.9872 0.8351 0.3732
unseen_class_acc=  0.6327676951885224
49 -0.8245 -1.6419 0.9885 0.8674 0.2623
unseen_class_acc=  0.6338293328881264
50 -0.7456 -1.4175 0.9897 0.7792 0.4247
unseen_class_acc=  0.6245015889406205
51 -0.7439 -1.3798 0.9893 0.7917 0.3230
unseen_class_acc=  0.6221081718802453
52 -0.7738 -1.5431 0.9904 0.8044 0.1619
unseen_class_acc=  0.6132220335304737
53 -0.7474 -1.6276 0.9904 0.7757 0.2666
unseen_class_acc=  0.636315432190895
54 -0.7268 -1.5919 0.9909 0.7662 0.3175
unseen_class_acc=  0.6295791506767273
55 -0.7422 -1.4904 0.9903 0.7720 0.4062
unseen_class_acc=  0.6275665044784546
56 -0.7348 -1.7038 0.9915 0.7724 0.1026
unseen_class_acc=  0.604671336710453
57 -0.8449 -1.6822 0.9922 0.9082 0.2548
unseen_class_acc=  0.6341266840696335
58 -0.8719 -1.4120 0.9914 0.9281 0.3073
unseen_class_acc=  0.6221975207328796
59 -0.7476 -1.6354 0.9900 0.7718 0.4489
unseen_class_acc=  0.6184912614524365
60 -0.8318 -1.6685 0.9915 0.8717 0.1318
unseen_class_acc=  0.6115031309425831
61 -0.7976 -1.6446 0.9908 0.8498 0.3818
unseen_class_acc=  0.6127943657338619
62 -0.7562 -1.5255 0.9913 0.7943 0.1159
unseen_class_acc=  0.6343223109841347
63 -0.7938 -1.6892 0.9920 0.8323 0.3016
unseen_class_acc=  0.6171928748488427
64 -0.8377 -1.6594 0.9927 0.8865 0.0851
unseen_class_acc=  0.6276788905262947
65 -0.8057 -1.6642 0.9915 0.8453 0.2504
unseen_class_acc=  0.6173886135220528
66 -0.8062 -1.7884 0.9921 0.8418 0.1594
unseen_class_acc=  0.6133753042668104
67 -0.7375 -1.7284 0.9932 0.7734 0.2050
unseen_class_acc=  0.6059271208941936
68 -0.7406 -1.7236 0.9928 0.7753 0.1163
unseen_class_acc=  0.612192713841796
69 -0.7975 -1.6834 0.9937 0.8302 0.1797
unseen_class_acc=  0.6276299558579922
70 -0.7982 -1.5081 0.9926 0.8529 0.1604
unseen_class_acc=  0.6198105476796627
71 -0.7747 -1.7386 0.9927 0.8159 0.1168
unseen_class_acc=  0.6196018358692527
72 -0.8325 -1.6799 0.9925 0.8748 0.1565
unseen_class_acc=  0.6154785260558129
73 -0.7662 -1.7434 0.9938 0.8015 0.1502
unseen_class_acc=  0.6231189172714948
74 -0.7225 -1.6489 0.9934 0.7633 0.0739
unseen_class_acc=  0.6343132678419352
75 -0.8060 -1.7305 0.9930 0.8531 0.1445
unseen_class_acc=  0.6311906781047583
76 -0.7926 -1.6849 0.9928 0.8360 0.1924
unseen_class_acc=  0.6115124778822064
77 -0.8022 -1.7469 0.9931 0.8543 0.2929
unseen_class_acc=  0.6192664066329598
78 -0.7841 -1.6757 0.9940 0.8255 0.1352
unseen_class_acc=  0.6270789589732886
79 -0.7924 -1.6924 0.9931 0.8513 0.0778
unseen_class_acc=  0.6276089701801538
80 -0.6968 -1.8001 0.9933 0.7446 0.2932
unseen_class_acc=  0.6359983384609222
81 -0.7583 -1.8974 0.9941 0.7985 0.0218
unseen_class_acc=  0.6295867204666138
82 -0.7740 -1.8176 0.9943 0.8089 0.1743
unseen_class_acc=  0.6182861860841513
83 -0.7857 -1.8107 0.9941 0.8262 0.2058
unseen_class_acc=  0.6253847252577543
84 -0.7506 -1.7625 0.9946 0.7882 0.0854
unseen_class_acc=  0.6234247539192438
85 -0.7664 -1.7997 0.9933 0.7999 0.1393
unseen_class_acc=  0.6346888648346066
86 -0.8015 -1.7018 0.9940 0.8494 0.1317
unseen_class_acc=  0.6064742254093289
87 -0.8026 -1.7116 0.9947 0.8513 0.0947
unseen_class_acc=  0.6185347063466906
88 -0.7466 -1.8436 0.9945 0.7939 0.0687
unseen_class_acc=  0.6368093989789486
89 -0.7002 -1.6648 0.9943 0.7371 0.0148
unseen_class_acc=  0.6190243621356786
90 -0.7151 -1.7424 0.9946 0.7426 0.1003
unseen_class_acc=  0.6140056865289807
91 -0.8643 -1.8175 0.9930 0.9198 0.2068
unseen_class_acc=  0.6164418106898666
92 -0.7626 -1.7469 0.9940 0.8167 0.0164
unseen_class_acc=  0.6108223249204456
93 -0.7219 -1.7550 0.9937 0.7565 0.0570
unseen_class_acc=  0.6104993121698499
94 -0.7750 -1.7619 0.9946 0.8159 0.0591
unseen_class_acc=  0.6285075886175037
95 -0.7513 -1.8376 0.9937 0.7910 0.0884
unseen_class_acc=  0.6208645929582417
96 -0.8119 -1.8720 0.9947 0.8481 0.1551
unseen_class_acc=  0.623756652045995
97 -0.7831 -1.6210 0.9944 0.8340 0.1019
unseen_class_acc=  0.6112418469507247
98 -0.7740 -1.6917 0.9950 0.8138 0.1042
unseen_class_acc=  0.601095972629264
99 -0.8300 -1.8520 0.9946 0.8663 0.1092
unseen_class_acc=  0.6176720936782658
