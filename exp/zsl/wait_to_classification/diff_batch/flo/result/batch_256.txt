Namespace(attSize=1024, batch_size=256, beta1=0.5, class_embedding='att', classifier_lr=0.001, cls_weight=0.1, critic_iter=5, cuda=True, dataroot='/data0/docker/xingyun/f_xGAN/data', dataset='FLO', drop_rate=0.2, gzsl=False, image_embedding='res101', lambda1=10.0, lr=0.0001, manualSeed=806, matdataset=True, nclass_all=200, ndh=4096, nepoch=100, netD='', netD_name='MLP_CRITIC', netG='', netG_name='MLP_G', ngh=4096, ngpu=1, nrh=4096, nrh1=1024, nrh2=512, nrh3=312, nrh4=156, nz=1024, outf='./checkpoint/', outname='flowers', preprocessing=True, pretrain_classifier='', print_every=1, r_iteration=3, r_path='/home/xingyun/docker/cycle_clsgan/r_param/', r_weight=1, resSize=2048, save_every=100, standardization=False, start_epoch=0, syn_num=300, val_every=1, validation=False, workers=2)
Random Seed:  806
cuda is on, sets the seed for generating random numbers on all GPU
# of training samples:  5631
MLP_G(
  (fc1): Linear(in_features=2048, out_features=4096)
  (fc2): Linear(in_features=4096, out_features=2048)
  (lrelu): LeakyReLU(0.2, inplace)
  (relu): ReLU(inplace)
)
MLP_CRITIC(
  (fc1): Linear(in_features=3072, out_features=4096)
  (fc2): Linear(in_features=4096, out_features=1)
  (lrelu): LeakyReLU(0.2, inplace)
)
MLP_1HL_Dropout_R(
  (fc1): Linear(in_features=2048, out_features=4096)
  (fc2): Linear(in_features=4096, out_features=1024)
  (lrelu): LeakyReLU(0.2, inplace)
  (relu): ReLU(inplace)
  (dropout): Dropout(p=0.2)
)
epoch lossG lossD lossR wDistance c_errG acc
0 -1.4508 -1.4325 0.6844 1.4727 5.1951
unseen_class_acc=  0.10280324248597025
1 -1.8865 -1.4269 0.7042 1.9073 5.2989
unseen_class_acc=  0.10448982631787658
2 -2.3146 -1.0861 0.7089 2.3631 4.9556
unseen_class_acc=  0.1902215641923249
3 -2.4178 -0.9084 0.7115 2.5622 4.6719
unseen_class_acc=  0.2135524746030569
4 -2.6008 -0.8045 0.7119 2.8190 4.4221
unseen_class_acc=  0.15301927980035543
5 -2.7454 -0.8883 0.7185 2.9456 4.3825
unseen_class_acc=  0.20341812036931514
6 -2.8440 -0.9128 0.7211 3.0257 4.3904
unseen_class_acc=  0.22871539015322923
7 -2.8908 -0.8411 0.7197 3.0854 4.3114
unseen_class_acc=  0.2148446414619684
8 -2.9150 -0.8604 0.7266 3.0705 4.2415
unseen_class_acc=  0.24363052258267998
9 -2.9400 -0.9109 0.7307 3.1043 4.0884
unseen_class_acc=  0.27661722237244246
10 -2.9912 -0.8549 0.7342 3.1969 4.0233
unseen_class_acc=  0.2800330699887127
11 -3.0079 -0.7957 0.7326 3.2254 4.0806
unseen_class_acc=  0.31854387540370227
12 -2.9627 -0.8052 0.7379 3.1641 3.8999
unseen_class_acc=  0.3258125993423164
13 -2.9729 -0.7679 0.7440 3.1752 3.7887
unseen_class_acc=  0.32398948366753755
14 -2.8938 -0.7745 0.7430 3.0786 3.6802
unseen_class_acc=  0.294206776143983
15 -3.0043 -0.7518 0.7417 3.2146 3.7527
unseen_class_acc=  0.3428614581003785
16 -2.8890 -0.6823 0.7495 3.0703 3.5241
unseen_class_acc=  0.34007169399410486
17 -2.8434 -0.7209 0.7511 2.9970 3.3758
unseen_class_acc=  0.39718989045359193
18 -2.8569 -0.5998 0.7521 3.0408 3.4578
unseen_class_acc=  0.4191897879354656
19 -2.7934 -0.5403 0.7498 2.9768 3.3479
unseen_class_acc=  0.40256379283964633
20 -2.8344 -0.5148 0.7537 2.9885 3.0534
unseen_class_acc=  0.39742972506210206
21 -2.7181 -0.4512 0.7547 2.8861 3.2843
unseen_class_acc=  0.4042315540835261
22 -2.6306 -0.3964 0.7583 2.7956 3.1151
unseen_class_acc=  0.4425727592781186
23 -2.6893 -0.3318 0.7577 2.8340 2.9919
unseen_class_acc=  0.3943566446658224
24 -2.6405 -0.2628 0.7547 2.8075 2.8166
unseen_class_acc=  0.41525074616074564
25 -2.7546 -0.1889 0.7554 2.8990 2.8763
unseen_class_acc=  0.4250952096655965
26 -2.6217 -0.2096 0.7644 2.7501 2.9236
unseen_class_acc=  0.4282827267423272
27 -2.6222 -0.1401 0.7587 2.7818 2.7393
unseen_class_acc=  0.44738126788288357
28 -2.5393 -0.0741 0.7623 2.6996 2.6503
unseen_class_acc=  0.4407626911997795
29 -2.5646 0.0398 0.7646 2.7105 2.5101
unseen_class_acc=  0.47160449642688035
30 -2.5046 0.0600 0.7651 2.6511 2.5311
unseen_class_acc=  0.4642751503735781
31 -2.4535 0.2216 0.7645 2.6335 2.4478
unseen_class_acc=  0.45806181579828265
32 -2.4222 0.1606 0.7676 2.5698 2.3606
unseen_class_acc=  0.47228952310979366
33 -2.4051 0.1938 0.7692 2.5285 2.5119
unseen_class_acc=  0.4734313514083624
34 -2.3494 0.2042 0.7699 2.4668 2.3177
unseen_class_acc=  0.4788281451910734
35 -2.3483 0.3068 0.7696 2.4870 2.3872
unseen_class_acc=  0.49233040064573286
36 -2.3852 0.3825 0.7684 2.5445 2.1824
unseen_class_acc=  0.4827053114771843
37 -2.3162 0.3829 0.7698 2.4466 2.3816
unseen_class_acc=  0.4790147732943296
38 -2.3067 0.4822 0.7709 2.4380 2.1476
unseen_class_acc=  0.49420342706143855
39 -2.2723 0.3904 0.7702 2.3798 2.1381
unseen_class_acc=  0.5095295075327158
40 -2.2450 0.4936 0.7677 2.3482 2.1929
unseen_class_acc=  0.4753904268145561
41 -2.1796 0.5104 0.7722 2.2865 2.0653
unseen_class_acc=  0.5085741609334946
42 -2.1929 0.6269 0.7721 2.3406 1.9788
unseen_class_acc=  0.49212716668844225
43 -2.1584 0.6857 0.7699 2.2632 1.8289
unseen_class_acc=  0.49115941785275935
44 -2.1517 0.7500 0.7722 2.2631 2.0357
unseen_class_acc=  0.522547771409154
45 -2.0981 0.7342 0.7732 2.2057 1.9802
unseen_class_acc=  0.5204428926110267
46 -2.0686 0.7489 0.7742 2.1744 1.9821
unseen_class_acc=  0.5115280702710152
47 -2.0826 0.8118 0.7711 2.1841 1.9115
unseen_class_acc=  0.5418167516589165
48 -1.9883 0.7937 0.7750 2.0687 1.9589
unseen_class_acc=  0.5299412593245506
49 -2.0012 0.8721 0.7758 2.1029 1.6944
unseen_class_acc=  0.5236123375594616
50 -2.0229 0.8131 0.7738 2.1163 1.8627
unseen_class_acc=  0.529119911044836
51 -1.9883 0.8728 0.7747 2.0767 1.9027
unseen_class_acc=  0.507695122808218
52 -1.9561 0.9137 0.7762 2.0512 1.8286
unseen_class_acc=  0.5270928639918566
53 -1.9131 1.0342 0.7749 1.9894 1.7472
unseen_class_acc=  0.5221455130726099
54 -1.8980 1.0217 0.7737 1.9701 1.7981
unseen_class_acc=  0.5394632115960121
55 -1.9294 1.0003 0.7734 2.0096 1.8171
unseen_class_acc=  0.5257556691765786
56 -1.8832 1.0152 0.7747 1.9687 1.7588
unseen_class_acc=  0.5377200797200203
57 -1.8601 1.0587 0.7746 1.9348 1.7808
unseen_class_acc=  0.5349168363958597
58 -1.8595 1.0946 0.7780 1.9549 1.7624
unseen_class_acc=  0.5389777742326259
59 -1.8287 1.1370 0.7749 1.9018 1.6342
unseen_class_acc=  0.5557894013822079
60 -1.8038 1.0542 0.7773 1.8804 1.6306
unseen_class_acc=  0.5561878988519311
61 -1.8015 1.0508 0.7779 1.8838 1.8009
unseen_class_acc=  0.5549849407747388
62 -1.7432 1.1089 0.7774 1.8162 1.6908
unseen_class_acc=  0.540836388617754
63 -1.7773 1.1401 0.7786 1.8504 1.4981
unseen_class_acc=  0.559344919025898
64 -1.8066 0.9343 0.7756 1.8825 1.5116
unseen_class_acc=  0.574319451674819
65 -1.7392 1.0880 0.7771 1.8182 1.5567
unseen_class_acc=  0.5741636976599693
66 -1.7125 1.0623 0.7796 1.7934 1.5882
unseen_class_acc=  0.5761680316179991
67 -1.6675 0.9771 0.7770 1.7455 1.5962
unseen_class_acc=  0.5652810866013169
68 -1.7425 0.9775 0.7769 1.8078 1.5108
unseen_class_acc=  0.5859597608447075
69 -1.6403 1.0351 0.7783 1.7137 1.5729
unseen_class_acc=  0.5784334475174546
70 -1.6613 0.9473 0.7793 1.7344 1.5963
unseen_class_acc=  0.5659361060708761
71 -1.5862 0.8662 0.7773 1.6511 1.6574
unseen_class_acc=  0.5897917241789401
72 -1.6134 0.9836 0.7804 1.6793 1.5139
unseen_class_acc=  0.5832223232835532
73 -1.6302 0.8701 0.7792 1.7159 1.5554
unseen_class_acc=  0.5767976004630327
74 -1.5736 0.9147 0.7803 1.6341 1.4093
unseen_class_acc=  0.5786485988646746
75 -1.5764 0.8028 0.7785 1.6473 1.4273
unseen_class_acc=  0.5855071503669024
76 -1.5007 0.8235 0.7811 1.5639 1.4072
unseen_class_acc=  0.5666289688088
77 -1.5122 0.8259 0.7796 1.5729 1.5560
unseen_class_acc=  0.5993490405380726
78 -1.5115 0.7527 0.7802 1.5791 1.3516
unseen_class_acc=  0.5796495327726007
79 -1.4945 0.6795 0.7798 1.5544 1.3914
unseen_class_acc=  0.6030528070405126
80 -1.4677 0.7792 0.7809 1.5291 1.4363
unseen_class_acc=  0.5840353922918439
81 -1.4660 0.6848 0.7812 1.5298 1.3516
unseen_class_acc=  0.5867703638970851
82 -1.3687 0.6693 0.7808 1.4309 1.2932
unseen_class_acc=  0.5811658818274736
83 -1.4257 0.6248 0.7815 1.4823 1.4134
unseen_class_acc=  0.5906869884580374
84 -1.4452 0.5211 0.7822 1.5067 1.2670
unseen_class_acc=  0.6002927780151367
85 -1.4392 0.4522 0.7823 1.4982 1.4200
unseen_class_acc=  0.5985656779259443
86 -1.4089 0.6009 0.7809 1.4662 1.4091
unseen_class_acc=  0.5871395219117403
87 -1.3798 0.4820 0.7816 1.4280 1.3636
unseen_class_acc=  0.5942709904164076
88 -1.3547 0.4110 0.7798 1.4050 1.4131
unseen_class_acc=  0.5902169559150934
89 -1.3650 0.3988 0.7812 1.4205 1.2202
unseen_class_acc=  0.5839383631944657
90 -1.3317 0.3315 0.7807 1.3845 1.2843
unseen_class_acc=  0.5967666499316693
91 -1.3395 0.1880 0.7807 1.3964 1.1192
unseen_class_acc=  0.6087694883346557
92 -1.3185 0.3246 0.7834 1.3748 1.4982
unseen_class_acc=  0.5999710828065872
93 -1.3006 0.1655 0.7816 1.3633 1.2747
unseen_class_acc=  0.597767549008131
94 -1.2974 0.0893 0.7810 1.3625 1.2923
unseen_class_acc=  0.5953180637210608
95 -1.2882 0.1589 0.7809 1.3494 1.2977
unseen_class_acc=  0.6030492387712002
96 -1.3323 0.0593 0.7832 1.3861 1.4796
unseen_class_acc=  0.6076780885457993
97 -1.2682 0.0482 0.7816 1.3212 1.4640
unseen_class_acc=  0.6051524907350541
98 -1.2511 -0.0267 0.7827 1.3137 1.2642
unseen_class_acc=  0.6188842415809631
99 -1.3257 -0.0937 0.7824 1.3865 1.2062
unseen_class_acc=  0.6108686562627554
