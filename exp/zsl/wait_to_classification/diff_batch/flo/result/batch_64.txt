Namespace(attSize=1024, batch_size=64, beta1=0.5, class_embedding='att', classifier_lr=0.001, cls_weight=0.1, critic_iter=5, cuda=True, dataroot='/data0/docker/xingyun/f_xGAN/data', dataset='FLO', drop_rate=0.2, gzsl=False, image_embedding='res101', lambda1=10.0, lr=0.0001, manualSeed=806, matdataset=True, nclass_all=200, ndh=4096, nepoch=100, netD='', netD_name='MLP_CRITIC', netG='', netG_name='MLP_G', ngh=4096, ngpu=1, nrh=4096, nrh1=1024, nrh2=512, nrh3=312, nrh4=156, nz=1024, outf='./checkpoint/', outname='flowers', preprocessing=True, pretrain_classifier='', print_every=1, r_iteration=3, r_path='/home/xingyun/docker/cycle_clsgan/r_param/', r_weight=1, resSize=2048, save_every=100, standardization=False, start_epoch=0, syn_num=300, val_every=1, validation=False, workers=2)
Random Seed:  806
cuda is on, sets the seed for generating random numbers on all GPU
# of training samples:  5631
MLP_G(
  (fc1): Linear(in_features=2048, out_features=4096)
  (fc2): Linear(in_features=4096, out_features=2048)
  (lrelu): LeakyReLU(0.2, inplace)
  (relu): ReLU(inplace)
)
MLP_CRITIC(
  (fc1): Linear(in_features=3072, out_features=4096)
  (fc2): Linear(in_features=4096, out_features=1)
  (lrelu): LeakyReLU(0.2, inplace)
)
MLP_1HL_Dropout_R(
  (fc1): Linear(in_features=2048, out_features=4096)
  (fc2): Linear(in_features=4096, out_features=1024)
  (lrelu): LeakyReLU(0.2, inplace)
  (relu): ReLU(inplace)
  (dropout): Dropout(p=0.2)
)
epoch lossG lossD lossR wDistance c_errG acc
0 -2.4024 -0.8806 0.7019 2.4935 4.9158
unseen_class_acc=  0.19007544568739831
1 -2.6859 -0.7641 0.7258 2.8363 4.3326
unseen_class_acc=  0.20467287451028823
2 -2.9135 -0.6971 0.7352 3.0822 4.0467
unseen_class_acc=  0.24721935973502696
3 -3.0630 -0.4989 0.7389 3.2734 3.9287
unseen_class_acc=  0.2945619367528707
4 -3.0280 -0.2594 0.7444 3.2384 3.6187
unseen_class_acc=  0.32320077447220685
5 -3.0779 -0.1213 0.7455 3.2783 3.4890
unseen_class_acc=  0.39149691835045813
6 -2.9320 0.1648 0.7528 3.1105 3.4884
unseen_class_acc=  0.4048234366811812
7 -2.9637 0.4285 0.7544 3.1295 3.2672
unseen_class_acc=  0.38564038146287205
8 -2.9132 0.5146 0.7600 3.0961 2.8545
unseen_class_acc=  0.4440977590158582
9 -2.6976 0.7675 0.7609 2.8638 2.8338
unseen_class_acc=  0.43054434400983155
10 -2.7609 0.8890 0.7685 2.9279 2.4409
unseen_class_acc=  0.4200190933421254
11 -2.7056 1.0782 0.7680 2.8549 2.4169
unseen_class_acc=  0.4562895890325308
12 -2.6581 1.3402 0.7668 2.8020 2.9471
unseen_class_acc=  0.4445179831236601
13 -2.4225 1.5075 0.7675 2.5785 1.9999
unseen_class_acc=  0.4457895141094923
14 -2.4356 1.6786 0.7663 2.5550 2.1098
unseen_class_acc=  0.4677642289549112
15 -2.4348 1.8125 0.7694 2.5658 2.0726
unseen_class_acc=  0.46384064145386217
16 -2.2590 1.8621 0.7730 2.3716 2.4041
unseen_class_acc=  0.45254337303340436
17 -2.3845 1.9585 0.7732 2.5294 2.2924
unseen_class_acc=  0.49304433539509773
18 -2.2556 2.0223 0.7775 2.3892 2.1041
unseen_class_acc=  0.5100422576069832
19 -2.1357 2.0505 0.7808 2.2507 2.0712
unseen_class_acc=  0.5189661376178265
20 -2.1613 2.0215 0.7771 2.2430 1.7472
unseen_class_acc=  0.5321091264486313
21 -2.0305 2.0180 0.7742 2.1435 1.9045
unseen_class_acc=  0.5493496872484684
22 -1.9511 2.0150 0.7751 2.0745 1.9125
unseen_class_acc=  0.5327730566263199
23 -1.9702 1.9094 0.7801 2.0521 1.5186
unseen_class_acc=  0.5457403155043721
24 -1.8625 1.8305 0.7783 1.9537 1.7560
unseen_class_acc=  0.563966092467308
25 -1.8951 1.7918 0.7793 1.9804 1.9041
unseen_class_acc=  0.5475311737507582
26 -1.9059 1.7848 0.7808 2.0055 1.6562
unseen_class_acc=  0.5624071519821883
27 -1.7181 1.6870 0.7792 1.8139 1.2131
unseen_class_acc=  0.5596435606479645
28 -1.8159 1.6095 0.7793 1.9135 1.2725
unseen_class_acc=  0.5431314799934626
29 -1.7078 1.6270 0.7845 1.8074 1.5100
unseen_class_acc=  0.5496276095509529
30 -1.6846 1.4512 0.7840 1.7630 1.2418
unseen_class_acc=  0.566625084169209
31 -1.7202 1.5140 0.7749 1.8075 1.5464
unseen_class_acc=  0.5513362418860197
32 -1.7132 1.4196 0.7788 1.8185 1.3108
unseen_class_acc=  0.5590425910428166
33 -1.5506 1.4014 0.7816 1.6189 1.4448
unseen_class_acc=  0.5729055061936379
34 -1.6278 1.4010 0.7804 1.7212 1.4534
unseen_class_acc=  0.5717643784359098
35 -1.4939 1.0977 0.7830 1.5769 1.5165
unseen_class_acc=  0.5790281083434821
36 -1.5491 1.2819 0.7822 1.6171 1.2716
unseen_class_acc=  0.5825777430087328
37 -1.4580 1.0386 0.7837 1.5313 1.2350
unseen_class_acc=  0.565170562826097
38 -1.4491 1.3465 0.7802 1.5309 1.4022
unseen_class_acc=  0.586902416497469
39 -1.3397 0.9849 0.7835 1.4121 1.0177
unseen_class_acc=  0.5817381344735623
40 -1.4271 1.0090 0.7845 1.4979 1.6488
unseen_class_acc=  0.5979037579149008
41 -1.5247 0.9231 0.7833 1.5978 1.2428
unseen_class_acc=  0.5919628608971834
42 -1.3090 0.9999 0.7895 1.3943 1.1996
unseen_class_acc=  0.5980050172656775
43 -1.3161 1.0118 0.7814 1.3876 1.2019
unseen_class_acc=  0.5899337250739336
44 -1.2602 1.0395 0.7850 1.3390 1.3552
unseen_class_acc=  0.599205133318901
45 -1.3468 0.6877 0.7841 1.4174 1.1771
unseen_class_acc=  0.6105932291597128
46 -1.4322 0.8008 0.7850 1.5061 1.1798
unseen_class_acc=  0.6084552485495806
47 -1.3125 0.8760 0.7886 1.3871 1.2992
unseen_class_acc=  0.5913547784090042
48 -1.2774 0.8250 0.7857 1.3606 1.1459
unseen_class_acc=  0.6155834797769785
49 -1.2679 0.7059 0.7851 1.3396 1.3932
unseen_class_acc=  0.606713623739779
50 -1.3459 0.7667 0.7840 1.4245 1.1384
unseen_class_acc=  0.6294191788882018
51 -1.2892 0.7022 0.7865 1.3506 1.0004
unseen_class_acc=  0.6038739021867514
52 -1.2878 0.9565 0.7846 1.3896 1.0437
unseen_class_acc=  0.6207703934982419
53 -1.3229 0.8801 0.7873 1.3924 1.0481
unseen_class_acc=  0.6078428387641907
54 -1.1881 0.6860 0.7852 1.2422 1.2190
unseen_class_acc=  0.6098466234281659
55 -1.3729 0.8033 0.7854 1.4444 1.1153
unseen_class_acc=  0.6030824527144432
56 -1.2143 0.8647 0.7875 1.2866 1.0777
unseen_class_acc=  0.6238787019625306
57 -1.3296 0.7380 0.7832 1.4043 1.1580
unseen_class_acc=  0.6217504315078258
58 -1.3778 0.6481 0.7880 1.4606 0.9892
unseen_class_acc=  0.6357913475483656
59 -1.4207 0.8133 0.7841 1.5118 1.2725
unseen_class_acc=  0.6125450138002634
60 -1.3227 0.6820 0.7874 1.4150 1.0170
unseen_class_acc=  0.645137720182538
61 -1.3048 0.9576 0.7893 1.3810 1.0411
unseen_class_acc=  0.6327645484358072
62 -1.1894 0.8866 0.7856 1.2526 0.9901
unseen_class_acc=  0.6230695025995374
63 -1.4489 0.8211 0.7849 1.5514 0.9201
unseen_class_acc=  0.6383028099313378
64 -1.2033 0.7974 0.7837 1.2568 0.9681
unseen_class_acc=  0.640011634118855
65 -1.2110 0.7820 0.7878 1.2687 1.0775
unseen_class_acc=  0.6321122955530882
66 -1.2570 0.6821 0.7872 1.3315 1.0933
unseen_class_acc=  0.6292812917381525
67 -1.2406 0.8026 0.7867 1.3059 0.8659
unseen_class_acc=  0.6435911262407898
68 -1.2637 0.7333 0.7885 1.3488 0.8527
unseen_class_acc=  0.6402042705565691
69 -1.2667 0.9892 0.7860 1.3290 0.9215
unseen_class_acc=  0.6366484683007002
70 -1.3587 0.7913 0.7882 1.4369 0.8420
unseen_class_acc=  0.6422245889902115
71 -1.2867 0.7096 0.7886 1.3546 0.6960
unseen_class_acc=  0.6545628756284714
72 -1.2746 0.9599 0.7838 1.3365 0.9593
unseen_class_acc=  0.6348838219419122
73 -1.2873 0.7877 0.7874 1.3658 0.7600
unseen_class_acc=  0.6458054291084409
74 -1.2420 0.7800 0.7870 1.3104 0.8615
unseen_class_acc=  0.6617360826581716
75 -1.1963 0.9408 0.7868 1.2594 0.9250
unseen_class_acc=  0.6476656036451459
76 -1.1863 0.7577 0.7902 1.2646 0.7194
unseen_class_acc=  0.6230071548372507
77 -1.1473 0.8405 0.7880 1.2117 0.7787
unseen_class_acc=  0.6431324258446693
78 -1.1336 0.8914 0.7892 1.1913 1.1308
unseen_class_acc=  0.6450298261828721
79 -1.1694 1.0549 0.7845 1.2504 0.8361
unseen_class_acc=  0.6392172183841467
80 -1.2294 0.9947 0.7861 1.3024 0.6806
unseen_class_acc=  0.6512536281719804
81 -1.2247 1.0674 0.7889 1.3126 1.0716
unseen_class_acc=  0.6466945931315422
82 -1.2568 1.0688 0.7900 1.3400 0.9420
unseen_class_acc=  0.6531865362077951
83 -1.2162 1.0862 0.7889 1.2826 1.0142
unseen_class_acc=  0.6338068604469299
84 -1.2682 1.1794 0.7893 1.3499 0.8619
unseen_class_acc=  0.6568000417202711
85 -1.1865 1.2462 0.7844 1.2497 0.6949
unseen_class_acc=  0.6446550641208887
86 -1.3438 0.8737 0.7835 1.4343 0.9179
unseen_class_acc=  0.6572346955537796
87 -1.1676 0.9314 0.7910 1.2527 0.7787
unseen_class_acc=  0.6459855267778039
88 -1.1957 0.7810 0.7916 1.2474 0.9087
unseen_class_acc=  0.6324208527803421
89 -1.2767 1.2346 0.7877 1.3620 0.5097
unseen_class_acc=  0.6343643415719271
90 -1.0979 1.2197 0.7850 1.1425 0.6138
unseen_class_acc=  0.6153433505445719
91 -1.1106 0.9863 0.7890 1.1654 0.7066
unseen_class_acc=  0.6484035279601812
92 -1.3245 1.1767 0.7868 1.3981 0.8452
unseen_class_acc=  0.6174179222434759
93 -1.1809 1.1544 0.7854 1.2345 0.5054
unseen_class_acc=  0.6396686244755984
94 -1.1781 1.1652 0.7898 1.2450 0.4956
unseen_class_acc=  0.6315702106803656
95 -1.2282 0.7863 0.7906 1.3052 0.7029
unseen_class_acc=  0.6165437083691359
96 -1.1853 1.1531 0.7880 1.2464 0.8422
unseen_class_acc=  0.6383022475987673
97 -1.2385 1.0422 0.7861 1.2905 0.5782
unseen_class_acc=  0.6603811379522085
98 -1.2209 0.8382 0.7904 1.2840 0.5440
unseen_class_acc=  0.6568002106621862
99 -1.2168 1.3717 0.7881 1.2809 1.1271
unseen_class_acc=  0.6442497987300158
