Namespace(attSize=85, batch_size=64, beta1=0.5, class_embedding='att', classifier_lr=0.001, cls_weight=0.01, critic_iter=5, cuda=True, dataroot='/data0/docker/xingyun/f_xGAN/data', dataset='AWA1', drop_rate=0.2, gzsl=False, image_embedding='res101', lambda1=10.0, lr=1e-05, manualSeed=9182, matdataset=True, nclass_all=200, ndh=4096, nepoch=100, netD='', netD_name='MLP_CRITIC', netG='', netG_name='MLP_G', ngh=4096, ngpu=1, nrh=4096, nrh1=1024, nrh2=512, nrh3=312, nrh4=156, nz=85, outf='./checkpoint/', outname='awa', preprocessing=True, pretrain_classifier='', print_every=1, r_iteration=3, r_path='/home/xingyun/docker/cycle_clsgan/r_param/', r_weight=1, resSize=2048, save_every=100, standardization=False, start_epoch=0, syn_num=300, val_every=1, validation=False, workers=2)
Random Seed:  9182
cuda is on, sets the seed for generating random numbers on all GPU
# of training samples:  19832
MLP_G(
  (fc1): Linear(in_features=170, out_features=4096)
  (fc2): Linear(in_features=4096, out_features=2048)
  (lrelu): LeakyReLU(0.2, inplace)
  (relu): ReLU(inplace)
)
MLP_CRITIC(
  (fc1): Linear(in_features=2133, out_features=4096)
  (fc2): Linear(in_features=4096, out_features=1)
  (lrelu): LeakyReLU(0.2, inplace)
)
MLP_4HL_Dropout_R(
  (fc1): Linear(in_features=2048, out_features=1024)
  (fc2): Linear(in_features=1024, out_features=512)
  (fc3): Linear(in_features=512, out_features=312)
  (fc4): Linear(in_features=312, out_features=156)
  (fc5): Linear(in_features=156, out_features=85)
  (relu): ReLU(inplace)
  (lrelu): LeakyReLU(0.2, inplace)
  (dropout): Dropout(p=0.2)
)
epoch lossG lossD lossR wDistance acc
0 -1.2172 -0.1263 0.7571 1.2825
unseen_class_acc=  0.18119364985614084
1 -1.8827 0.0534 0.7945 1.9907
unseen_class_acc=  0.3370147138834
2 -1.7730 -0.1921 0.7826 1.8558
unseen_class_acc=  0.3040714915841818
3 -1.3304 -0.2563 0.7885 1.3747
unseen_class_acc=  0.39307045135647056
4 -1.0029 -0.4216 0.8476 1.0357
unseen_class_acc=  0.47692474741488694
5 -0.9557 -0.4955 0.8785 0.9916
unseen_class_acc=  0.4277655817568302
6 -0.9451 -0.5306 0.8751 0.9849
unseen_class_acc=  0.4810664504766464
7 -0.7277 -0.5125 0.9021 0.7515
unseen_class_acc=  0.4773284733295441
8 -0.8113 -0.6565 0.9156 0.8381
unseen_class_acc=  0.4753724932670593
9 -0.8138 -0.6596 0.9202 0.8452
unseen_class_acc=  0.4915754243731499
10 -0.7973 -0.5446 0.9360 0.8245
unseen_class_acc=  0.5299242660403252
11 -0.7281 -0.5956 0.9355 0.7587
unseen_class_acc=  0.5209093287587165
12 -0.8207 -0.7931 0.9381 0.8560
unseen_class_acc=  0.5482494011521339
13 -0.6941 -0.6707 0.9440 0.7273
unseen_class_acc=  0.5496250987052917
14 -0.7321 -0.8456 0.9477 0.7721
unseen_class_acc=  0.5745567806065083
15 -0.8356 -0.8273 0.9557 0.8742
unseen_class_acc=  0.6022537901997567
16 -0.7407 -0.8305 0.9619 0.7714
unseen_class_acc=  0.6218007072806359
17 -0.9091 -0.7668 0.9623 0.9518
unseen_class_acc=  0.634707760810852
18 -0.7980 -0.9946 0.9631 0.8348
unseen_class_acc=  0.6311139583587646
19 -0.8482 -1.0484 0.9657 0.8894
unseen_class_acc=  0.6416555747389794
20 -0.7871 -1.0127 0.9638 0.8206
unseen_class_acc=  0.6375338941812515
21 -0.8668 -0.9685 0.9668 0.8999
unseen_class_acc=  0.6489426955580712
22 -0.8245 -1.1953 0.9719 0.8636
unseen_class_acc=  0.6481420546770096
23 -0.8594 -1.0225 0.9734 0.8921
unseen_class_acc=  0.6606687054038047
24 -0.8056 -1.1333 0.9730 0.8336
unseen_class_acc=  0.6587017878890038
25 -0.8683 -1.1827 0.9724 0.9016
unseen_class_acc=  0.663893349468708
26 -0.8244 -1.1889 0.9731 0.8548
unseen_class_acc=  0.6655183270573616
27 -0.7418 -1.2305 0.9745 0.7782
unseen_class_acc=  0.6417282372713089
28 -0.7665 -1.2568 0.9786 0.7903
unseen_class_acc=  0.668082919716835
29 -0.7933 -1.4368 0.9769 0.8291
unseen_class_acc=  0.660949033498764
30 -0.7354 -1.3257 0.9768 0.7658
unseen_class_acc=  0.6590228274464607
31 -0.7655 -1.3159 0.9790 0.8060
unseen_class_acc=  0.689313730597496
32 -0.8112 -1.1980 0.9809 0.8487
unseen_class_acc=  0.6622198954224586
33 -0.8228 -1.5247 0.9811 0.8607
unseen_class_acc=  0.674040675163269
34 -0.8679 -1.4867 0.9817 0.8985
unseen_class_acc=  0.6670678675174713
35 -0.8065 -1.3513 0.9798 0.8412
unseen_class_acc=  0.6482579603791236
36 -0.7714 -1.4675 0.9811 0.8065
unseen_class_acc=  0.6475677534937858
37 -0.8188 -1.6413 0.9812 0.8515
unseen_class_acc=  0.6657509058713913
38 -0.7378 -1.5111 0.9848 0.7695
unseen_class_acc=  0.6685132384300232
39 -0.8556 -1.4218 0.9844 0.8920
unseen_class_acc=  0.6399210333824158
40 -0.7495 -1.5240 0.9862 0.7875
unseen_class_acc=  0.6507013350725174
41 -0.8064 -1.5159 0.9829 0.8426
unseen_class_acc=  0.6626945957541466
42 -0.7783 -1.6081 0.9847 0.8074
unseen_class_acc=  0.6452746525406837
43 -0.8194 -1.5132 0.9845 0.8578
unseen_class_acc=  0.6602195531129837
44 -0.8709 -1.6305 0.9865 0.9065
unseen_class_acc=  0.6480488643050194
45 -0.8283 -1.4659 0.9873 0.8652
unseen_class_acc=  0.647085751593113
46 -0.7551 -1.6369 0.9889 0.7847
unseen_class_acc=  0.6514469519257545
47 -0.7477 -1.6351 0.9894 0.7836
unseen_class_acc=  0.6456175073981285
48 -0.7152 -1.6966 0.9886 0.7421
unseen_class_acc=  0.6489008843898774
49 -0.8381 -1.6008 0.9886 0.8776
unseen_class_acc=  0.6452755615115165
50 -0.8290 -1.4229 0.9876 0.8702
unseen_class_acc=  0.6421247139573097
51 -0.8111 -1.5735 0.9879 0.8480
unseen_class_acc=  0.6235886156558991
52 -0.8028 -1.6618 0.9871 0.8649
unseen_class_acc=  0.6395616963505745
53 -0.7095 -1.6574 0.9905 0.7352
unseen_class_acc=  0.6476223409175873
54 -0.7984 -1.6582 0.9899 0.8239
unseen_class_acc=  0.6341053649783135
55 -0.7278 -1.6966 0.9902 0.7618
unseen_class_acc=  0.6365990325808525
56 -0.6953 -1.6427 0.9883 0.7241
unseen_class_acc=  0.648468466103077
57 -0.7722 -1.7894 0.9895 0.8053
unseen_class_acc=  0.6326409682631493
58 -0.8187 -1.7273 0.9883 0.8552
unseen_class_acc=  0.630151578783989
59 -0.7541 -1.7780 0.9888 0.7762
unseen_class_acc=  0.6347553759813309
60 -0.7503 -1.6481 0.9917 0.7830
unseen_class_acc=  0.6100185148417949
61 -0.7669 -1.7802 0.9921 0.7950
unseen_class_acc=  0.617485798895359
62 -0.7198 -1.7939 0.9914 0.7655
unseen_class_acc=  0.6185505896806717
63 -0.8141 -1.6546 0.9903 0.8412
unseen_class_acc=  0.6373962223529815
64 -0.7683 -1.9122 0.9916 0.7992
unseen_class_acc=  0.6233625501394272
65 -0.7478 -1.7140 0.9923 0.7794
unseen_class_acc=  0.6282647803425789
66 -0.8532 -1.7018 0.9924 0.8942
unseen_class_acc=  0.6248228035867214
67 -0.8544 -1.8692 0.9905 0.9094
unseen_class_acc=  0.6235427163541317
68 -0.8499 -1.7702 0.9917 0.8962
unseen_class_acc=  0.6149659991264343
69 -0.8249 -1.7495 0.9924 0.8655
unseen_class_acc=  0.6371770791709424
70 -0.6924 -1.7973 0.9914 0.7300
unseen_class_acc=  0.6449867531657218
71 -0.8256 -1.8368 0.9925 0.8675
unseen_class_acc=  0.6221140190958977
72 -0.7261 -1.7487 0.9920 0.7703
unseen_class_acc=  0.6465498700737953
73 -0.7535 -1.8029 0.9934 0.7944
unseen_class_acc=  0.6172518189996481
74 -0.7794 -1.7672 0.9915 0.8190
unseen_class_acc=  0.6348656587302685
75 -0.7228 -1.6546 0.9924 0.7527
unseen_class_acc=  0.644285038113594
76 -0.7922 -1.7145 0.9926 0.8258
unseen_class_acc=  0.6127620939165354
77 -0.8342 -1.6243 0.9921 0.8712
unseen_class_acc=  0.6306443072855472
78 -0.7878 -1.7903 0.9926 0.8344
unseen_class_acc=  0.6120290709659457
79 -0.7486 -1.9587 0.9930 0.7867
unseen_class_acc=  0.6306730756536126
80 -0.7447 -1.8409 0.9924 0.7953
unseen_class_acc=  0.6297920662909746
81 -0.7708 -1.7891 0.9936 0.8371
unseen_class_acc=  0.6187710111960769
82 -0.7862 -1.8425 0.9924 0.8310
unseen_class_acc=  0.6221506725996733
83 -0.8154 -1.9199 0.9931 0.8731
unseen_class_acc=  0.6442405112087727
84 -0.7877 -1.7519 0.9939 0.8238
unseen_class_acc=  0.6179890781641006
85 -0.7976 -1.7959 0.9925 0.8497
unseen_class_acc=  0.6231560695916414
86 -0.8091 -1.7793 0.9919 0.8472
unseen_class_acc=  0.6105520185083151
87 -0.7679 -1.8613 0.9925 0.8004
unseen_class_acc=  0.6373598627746105
88 -0.8443 -1.7972 0.9922 0.8922
unseen_class_acc=  0.6182193298824131
89 -0.8416 -1.7550 0.9936 0.8882
unseen_class_acc=  0.6292523592710495
90 -0.8299 -1.8046 0.9940 0.8768
unseen_class_acc=  0.6130731290206313
91 -0.7340 -1.8578 0.9938 0.7728
unseen_class_acc=  0.6195064965635538
92 -0.7890 -1.9995 0.9942 0.8165
unseen_class_acc=  0.6477387387305498
93 -0.7502 -1.8076 0.9945 0.7886
unseen_class_acc=  0.6339137752540409
94 -0.7828 -1.7926 0.9938 0.8275
unseen_class_acc=  0.6190759109333157
95 -0.7620 -1.9778 0.9948 0.8076
unseen_class_acc=  0.6281831124797463
96 -0.7228 -1.8946 0.9934 0.7672
unseen_class_acc=  0.627034904807806
97 -0.8206 -1.9239 0.9936 0.8700
unseen_class_acc=  0.617430226970464
98 -0.8127 -1.7768 0.9941 0.8738
unseen_class_acc=  0.6199877096340061
99 -0.8095 -1.9146 0.9943 0.8647
unseen_class_acc=  0.6106894979253411
