Namespace(attSize=1024, batch_size=64, beta1=0.5, class_embedding='att', classifier_lr=0.001, cls_weight=0.1, critic_iter=5, cuda=True, dataroot='/data0/docker/xingyun/f_xGAN/data', dataset='FLO', drop_rate=0.2, gzsl=False, image_embedding='res101', lambda1=10.0, lr=0.0001, manualSeed=806, matdataset=True, nclass_all=200, ndh=4096, nepoch=100, netD='', netD_name='MLP_CRITIC', netG='', netG_name='MLP_G', ngh=4096, ngpu=1, nrh=4096, nrh1=1024, nrh2=512, nrh3=312, nrh4=156, nz=1024, outf='./checkpoint/', outname='flowers', preprocessing=True, pretrain_classifier='', print_every=1, r_iteration=3, r_path='/home/xingyun/docker/cycle_clsgan/r_param/', r_weight=1, resSize=2048, save_every=100, standardization=False, start_epoch=0, syn_num=300, val_every=1, validation=False, workers=2)
Random Seed:  806
cuda is on, sets the seed for generating random numbers on all GPU
# of training samples:  5631
MLP_G(
  (fc1): Linear(in_features=2048, out_features=4096)
  (fc2): Linear(in_features=4096, out_features=2048)
  (lrelu): LeakyReLU(0.2, inplace)
  (relu): ReLU(inplace)
)
MLP_CRITIC(
  (fc1): Linear(in_features=3072, out_features=4096)
  (fc2): Linear(in_features=4096, out_features=1)
  (lrelu): LeakyReLU(0.2, inplace)
)
MLP_1HL_Dropout_R(
  (fc1): Linear(in_features=2048, out_features=4096)
  (fc2): Linear(in_features=4096, out_features=1024)
  (lrelu): LeakyReLU(0.2, inplace)
  (relu): ReLU(inplace)
  (dropout): Dropout(p=0.2)
)
epoch lossG lossD lossR wDistance acc
0 -2.3520 -0.7796 0.7084 2.4438
unseen_class_acc=  0.10646094242110848
1 -2.6613 -0.6714 0.7237 2.7869
unseen_class_acc=  0.11426443252712488
2 -2.9623 -0.5051 0.7154 3.1451
unseen_class_acc=  0.17615582924336196
3 -3.0803 -0.4641 0.7226 3.2839
unseen_class_acc=  0.2462108342908323
4 -3.0725 -0.1702 0.7351 3.3031
unseen_class_acc=  0.22538286596536636
5 -2.9228 -0.1145 0.7403 3.1322
unseen_class_acc=  0.29084389861673116
6 -2.7776 0.0560 0.7516 2.9556
unseen_class_acc=  0.30821342184208333
7 -2.9388 0.3447 0.7528 3.1331
unseen_class_acc=  0.347531009837985
8 -2.8195 0.5389 0.7440 2.9918
unseen_class_acc=  0.30456751920282843
9 -2.7015 0.6448 0.7455 2.8344
unseen_class_acc=  0.32196328868158164
10 -2.5778 0.7729 0.7564 2.7327
unseen_class_acc=  0.3354532090481371
11 -2.4001 0.9226 0.7510 2.5448
unseen_class_acc=  0.3585500556975603
12 -2.3748 1.0851 0.7576 2.4865
unseen_class_acc=  0.3666241223458201
13 -2.2885 1.3038 0.7562 2.4156
unseen_class_acc=  0.36028114687651397
14 -2.1417 1.5193 0.7610 2.2694
unseen_class_acc=  0.37895081415772436
15 -2.1798 1.6150 0.7612 2.2984
unseen_class_acc=  0.39795128218829634
16 -2.0826 1.7676 0.7645 2.1933
unseen_class_acc=  0.3769726068712771
17 -2.0562 1.6827 0.7717 2.1656
unseen_class_acc=  0.43038457408547404
18 -1.9920 1.8062 0.7735 2.1229
unseen_class_acc=  0.4514646027237177
19 -1.9250 1.7832 0.7682 2.0155
unseen_class_acc=  0.4441637422889471
20 -1.9767 1.7120 0.7700 2.0623
unseen_class_acc=  0.4801648151129484
21 -1.8438 1.6663 0.7740 1.9261
unseen_class_acc=  0.4954817596822977
22 -1.7996 1.6236 0.7708 1.8834
unseen_class_acc=  0.4870976723730564
23 -1.9411 1.5816 0.7723 2.0383
unseen_class_acc=  0.5209393680095673
24 -1.8034 1.5150 0.7734 1.8988
unseen_class_acc=  0.5315989203751087
25 -1.6303 1.6458 0.7731 1.6992
unseen_class_acc=  0.53731270134449
26 -1.5666 1.3029 0.7788 1.6703
unseen_class_acc=  0.5381089247763157
27 -1.5751 1.2172 0.7777 1.6546
unseen_class_acc=  0.519318975508213
28 -1.6115 1.0031 0.7748 1.6902
unseen_class_acc=  0.5401352539658546
29 -1.4881 0.9599 0.7761 1.5842
unseen_class_acc=  0.5439772173762322
30 -1.4848 0.8820 0.7792 1.5503
unseen_class_acc=  0.5445483662188053
31 -1.4805 0.7940 0.7820 1.5675
unseen_class_acc=  0.5568856291472912
32 -1.5777 0.6389 0.7803 1.6642
unseen_class_acc=  0.5418134465813637
33 -1.4790 0.8015 0.7865 1.5756
unseen_class_acc=  0.5723130028694868
34 -1.3450 0.2982 0.7853 1.4179
unseen_class_acc=  0.5798906221985817
35 -1.3768 0.3512 0.7794 1.4430
unseen_class_acc=  0.5910925790667534
36 -1.4571 0.3366 0.7793 1.5405
unseen_class_acc=  0.5575437739491462
37 -1.3827 0.1072 0.7820 1.4771
unseen_class_acc=  0.5479259368032217
38 -1.4328 0.1761 0.7807 1.5220
unseen_class_acc=  0.5493986710906029
39 -1.3420 -0.1365 0.7811 1.4195
unseen_class_acc=  0.5615594405680895
40 -1.3320 0.0029 0.7800 1.4152
unseen_class_acc=  0.5675244078040123
41 -1.3479 -0.1964 0.7827 1.4203
unseen_class_acc=  0.5643695078790187
42 -1.3298 -0.4006 0.7835 1.4045
unseen_class_acc=  0.6096599087119102
43 -1.3589 0.0556 0.7823 1.4375
unseen_class_acc=  0.5786930620670319
44 -1.1605 -0.4557 0.7814 1.2281
unseen_class_acc=  0.6205729849636554
45 -1.3114 -0.4543 0.7808 1.3990
unseen_class_acc=  0.6082469727844
46 -1.3469 -0.4808 0.7791 1.4334
unseen_class_acc=  0.6045025002211333
47 -1.3591 -0.4910 0.7851 1.4590
unseen_class_acc=  0.5847599867731332
48 -1.3338 -0.8074 0.7821 1.4244
unseen_class_acc=  0.6344368178397417
49 -1.2908 -0.7128 0.7817 1.3920
unseen_class_acc=  0.6168008808046579
50 -1.3130 -0.9618 0.7841 1.3977
unseen_class_acc=  0.6216431928798556
51 -1.2327 -0.7794 0.7834 1.2906
unseen_class_acc=  0.6118419151753187
52 -1.3938 -0.7730 0.7837 1.4936
unseen_class_acc=  0.6159703079611063
53 -1.2924 -1.0553 0.7800 1.3629
unseen_class_acc=  0.6023840438574553
54 -1.3606 -1.2448 0.7871 1.4378
unseen_class_acc=  0.5824794203042984
55 -1.3698 -0.6058 0.7816 1.4421
unseen_class_acc=  0.6037115374580025
56 -1.3401 -0.9321 0.7830 1.4322
unseen_class_acc=  0.6446147162467242
57 -1.2706 -0.8117 0.7829 1.3552
unseen_class_acc=  0.6263280691578984
58 -1.3502 -0.8202 0.7835 1.4319
unseen_class_acc=  0.6037596095353365
59 -1.3137 -1.1172 0.7837 1.3576
unseen_class_acc=  0.6121039705350995
60 -1.3121 -1.3349 0.7888 1.3752
unseen_class_acc=  0.6116412749513984
61 -1.1574 -0.8912 0.7846 1.2228
unseen_class_acc=  0.6191434890031815
62 -1.2784 -1.1292 0.7848 1.3485
unseen_class_acc=  0.5922975743189454
63 -1.3099 -1.2861 0.7882 1.4100
unseen_class_acc=  0.5853721315041185
64 -1.2725 -1.3896 0.7818 1.3364
unseen_class_acc=  0.6221585066989064
65 -1.3195 -1.1745 0.7860 1.3822
unseen_class_acc=  0.6174313083291054
66 -1.3030 -1.2935 0.7855 1.3859
unseen_class_acc=  0.611766941472888
67 -1.3533 -1.4422 0.7836 1.4164
unseen_class_acc=  0.6306280490010977
68 -1.2993 -1.4317 0.7830 1.3832
unseen_class_acc=  0.6065648343414068
69 -1.4070 -1.4669 0.7865 1.5133
unseen_class_acc=  0.6227815160527825
70 -1.2140 -1.4453 0.7845 1.2874
unseen_class_acc=  0.6194050159305334
71 -1.2989 -1.3788 0.7869 1.3887
unseen_class_acc=  0.6269801676273346
72 -1.2489 -1.5993 0.7867 1.3090
unseen_class_acc=  0.6493949223309755
73 -1.2218 -1.5577 0.7861 1.2943
unseen_class_acc=  0.624873329140246
74 -1.3061 -1.6205 0.7872 1.3770
unseen_class_acc=  0.6027494695037603
75 -1.2577 -1.2188 0.7823 1.3340
unseen_class_acc=  0.6307451585307717
76 -1.2852 -1.5933 0.7887 1.3486
unseen_class_acc=  0.6163522148504853
77 -1.2354 -1.5994 0.7881 1.3136
unseen_class_acc=  0.6386029072105884
78 -1.3307 -1.5809 0.7884 1.4169
unseen_class_acc=  0.6225766459479928
79 -1.2747 -1.1753 0.7862 1.3431
unseen_class_acc=  0.6529393503442407
80 -1.3142 -1.6699 0.7859 1.3937
unseen_class_acc=  0.6265779856592417
81 -1.2518 -1.6415 0.7895 1.3130
unseen_class_acc=  0.6252320060506463
82 -1.2159 -1.7168 0.7850 1.2709
unseen_class_acc=  0.6466597143560648
83 -1.2496 -1.5539 0.7840 1.3334
unseen_class_acc=  0.6427320072427392
84 -1.1983 -1.5024 0.7888 1.2605
unseen_class_acc=  0.6542130872607231
85 -1.3515 -2.0096 0.7889 1.4339
unseen_class_acc=  0.6331648180261255
86 -1.3363 -1.7951 0.7843 1.4124
unseen_class_acc=  0.6295148983597756
87 -1.2620 -1.6766 0.7878 1.3408
unseen_class_acc=  0.6230787863023579
88 -1.3091 -1.5258 0.7877 1.4020
unseen_class_acc=  0.6437575315125287
89 -1.2607 -1.9866 0.7885 1.3539
unseen_class_acc=  0.6326497867703438
90 -1.1181 -2.1972 0.7870 1.1935
unseen_class_acc=  0.6320312649011612
91 -1.2793 -1.8701 0.7905 1.3664
unseen_class_acc=  0.636619682610035
92 -1.1648 -1.8217 0.7879 1.2392
unseen_class_acc=  0.6187474887818099
93 -1.1518 -1.7135 0.7885 1.2371
unseen_class_acc=  0.646613834425807
94 -1.1125 -1.5104 0.7891 1.1793
unseen_class_acc=  0.6276314869523049
95 -1.2061 -1.9264 0.7900 1.2822
unseen_class_acc=  0.648798886872828
96 -1.2846 -1.6160 0.7839 1.3535
unseen_class_acc=  0.6312783628702163
97 -1.2305 -1.4794 0.7868 1.2947
unseen_class_acc=  0.6319054344668984
98 -1.2202 -1.9305 0.7894 1.2843
unseen_class_acc=  0.6371720042079687
99 -1.1630 -1.9880 0.7906 1.2356
unseen_class_acc=  0.6137033727020025
